{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "class ClueKind(Enum):\n",
    "    HEADER=1\n",
    "    BODY=2\n",
    "clue_kind=ClueKind.HEADER\n",
    "model_parent_path = os.getcwd()\n",
    "model_path = 'google-t5/new_t5-3b_arc_ir_combine_header_train_epoch_0__eval_arc_ir_easy_header_test_acc_84.34.pkl'\n",
    "model_name = None\n",
    "tokenizer_name = \"google-t5/t5-3b\"\n",
    "max_answer_length = 300\n",
    "BATCH_SIZE = 10\n",
    "accumulate_step = None\n",
    "DATA_NAME_SINGLE = \"arc_ir_challenge_header_test\"\n",
    "NUM_EPOCHS = 1\n",
    "VISIBLE_DEVICE = \"1\"\n",
    "DEVICE = 0\n",
    "TO_WRITE_OUT=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loi params: google-t5/new_t5-3b_arc_ir_combine_header_train_epoch_0__eval_arc_ir_easy_header_test_acc_84.34.pkl#####300#####batch_size=10;accumulate_step=None\n"
     ]
    }
   ],
   "source": [
    "clue_kind=ClueKind(clue_kind)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(VISIBLE_DEVICE)  # cannot work\n",
    "print(\n",
    "    f\"Loi params: {model_path}{'#'*5}{max_answer_length}{'#'*5}batch_size={BATCH_SIZE};accumulate_step={accumulate_step}\"\n",
    ")\n",
    "DATABASE_NAME = [DATA_NAME_SINGLE]  # ,'arc_hard']#,'race','mctest',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/cvp352/loi_work/env/loi/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Adafactor\n",
    "from functools import wraps, partial\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "from tqdm import trange, tqdm\n",
    "from random_utils import set_seed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = []\n",
    "[dataset_test.append([]) for x in DATABASE_NAME]\n",
    "moi_index = []\n",
    "# TO_TEST=False\n",
    "for i, dataname in enumerate(DATABASE_NAME):\n",
    "    dataset_test[i] = pickle.load(\n",
    "        open(f\"multiple_choice_datasets/{dataname}.pkl\", \"rb\")\n",
    "    )\n",
    "# TO_TEST=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9853ca40c145a99b470b3ea6918b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = \"loi_with_padding_just_same_answer_len_70.pkl\"\n",
    "\n",
    "# \"loi_with_padding_1.pkl\"#\n",
    "# model_name = (\n",
    "#     \"allenai/unifiedqa-v2-t5-large-1363200\"  # you can specify the model size here\n",
    "# )\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "model_original = (\n",
    "    T5ForConditionalGeneration.from_pretrained(\n",
    "        f\"{model_parent_path}/{model_path}\", device_map=\"auto\"\n",
    "    )\n",
    "    if model_path\n",
    "    else T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\")\n",
    ")\n",
    "model = model_original\n",
    "# model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planetary days will become shorter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "# dataset_test[0][0]\n",
    "# ques=4\n",
    "dataset_test[0][0][1]\n",
    "# print('correct: ',dataset_test[ques][1],'length',len(dataset_test[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def hook(hook_before, oldfunc, hook_after):\n",
    "\n",
    "    def foo(*args, **kwargs):\n",
    "        hook_before(*args, **kwargs)\n",
    "        aa = oldfunc(*args, **kwargs)\n",
    "        hook_after(*args, **kwargs)\n",
    "        return aa\n",
    "\n",
    "    return foo\n",
    "def new_compute_bias(self, query_length, key_length, device=None):\n",
    "    \"\"\"Compute binned relative position bias\"\"\"\n",
    "    if device is None:\n",
    "        device = self.relative_attention_bias.weight.device\n",
    "    context_position = torch.arange(query_length, dtype=torch.long, device=device)[\n",
    "        :, None\n",
    "    ]\n",
    "    memory_position = torch.arange(key_length, dtype=torch.long, device=device)[None, :]\n",
    "\n",
    "    relative_position = (\n",
    "        memory_position - context_position\n",
    "    )  # shape (query_length, key_length)\n",
    "    if self.is_decoder:\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(\n",
    "            0\n",
    "        )  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    anchors = self.anchor_array\n",
    "    values = []\n",
    "    for anchor in anchors:\n",
    "        mot = [[anchor[idx], anchor[idx + 1]] for idx in range(len(anchor) - 1)]\n",
    "        if len(mot)>0:\n",
    "            max_answer_length = max([x[1] - x[0] for x in mot])\n",
    "            # print(a, b, c, d, max_answer_length)\n",
    "            context_position_new = context_position.clone()\n",
    "            for i in range(1, len(mot)):\n",
    "                context_position_new[mot[i][0] : mot[i][1]] = (\n",
    "                    context_position_new[mot[i][0] : mot[i][1]] - mot[0][0]\n",
    "                )\n",
    "            context_position_new[-1] = mot[0][0] + 2 * max_answer_length\n",
    "            memory_position_new = context_position_new.clone().view(1, -1)\n",
    "            relative_position = (\n",
    "                memory_position_new - context_position_new\n",
    "            )  # shape (query_length, key_length)\n",
    "            for i in range(len(mot)):\n",
    "                for j in range(len(mot)):\n",
    "                    if i != j:\n",
    "                        x = mot[i]\n",
    "                        y = mot[j]\n",
    "                        relative_position[x[0] : x[1], y[0] : y[1]] += max_answer_length\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        value = self.relative_attention_bias(relative_position_bucket)\n",
    "        values.append(value)\n",
    "    values = torch.stack(values)  # shape [1, 91, 91, 16]\n",
    "    values = values.permute(\n",
    "        [0, 3, 1, 2]\n",
    "    )  # shape (batch size, num_heads, query_length, key_length)\n",
    "    return values\n",
    "import textwrap\n",
    "\n",
    "\n",
    "extra_dim_learning = []\n",
    "\n",
    "\n",
    "def set_mode(MODE):\n",
    "    itself = model.encoder.block[0].layer[0].SelfAttention\n",
    "    if MODE == \"new\":\n",
    "        itself.compute_bias = partial(new_compute_bias, itself)\n",
    "        model.forward = hook(\n",
    "            input_before_hooker,\n",
    "            partial(T5ForConditionalGeneration.forward, model),\n",
    "            input_after_hooker,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        itself.compute_bias = partial(\n",
    "            model.encoder.block[0].layer[0].SelfAttention.__class__.compute_bias, itself\n",
    "        )\n",
    "        model.forward = partial(T5ForConditionalGeneration.forward, model)\n",
    "\n",
    "\n",
    "def check_encoded(all_input_ids):\n",
    "    anchors = []\n",
    "    for input_ids in all_input_ids:\n",
    "        # print('\\n'.join([f'{x.item()},{y}' for x,y in zip(input_ids, tokens)][50:]))\n",
    "        original = input_ids.tolist()\n",
    "        anchor = []\n",
    "        for i in range(len(input_ids)):\n",
    "            if (\n",
    "                i < len(input_ids) - 2\n",
    "                and input_ids[i] == 41\n",
    "                and input_ids[i + 1] == 3\n",
    "                and input_ids[i + 2] == 61\n",
    "            ) or original[i] == 1:\n",
    "                anchor.append(i)\n",
    "        anchors.append(anchor)\n",
    "    return anchors\n",
    "\n",
    "\n",
    "def input_before_hooker(*args, **kwargs):\n",
    "    input_ids = kwargs[\"input_ids\"]\n",
    "    # print('old ',input_ids)\n",
    "    anchors = check_encoded(input_ids)\n",
    "    final_inputs = []\n",
    "    for input_id, anchor in zip(input_ids, anchors):\n",
    "        input_id = input_id.tolist()\n",
    "        if len(anchor)>1:\n",
    "            real_max_len = max(\n",
    "                [anchor[idx + 1] - anchor[idx] for idx in range(len(anchor) - 1)]\n",
    "            )\n",
    "            if real_max_len > max_answer_length:\n",
    "                print(f\"ALERT: MAX LENGTH IS {real_max_len}\")\n",
    "            for x in reversed(range(1, len(anchor))):\n",
    "                if anchor[x] - anchor[x - 1] < max_answer_length:\n",
    "                    [\n",
    "                        input_id.insert(anchor[x], 0)\n",
    "                        for _ in range(max_answer_length - (anchor[x] - anchor[x - 1]))\n",
    "                    ]\n",
    "\n",
    "        final_inputs.append(input_id)\n",
    "\n",
    "    max_length = max([len(input) for input in final_inputs])\n",
    "    mask = [[1] * max_length] * len(final_inputs)\n",
    "    for idx, input in enumerate(final_inputs):\n",
    "        for x in range(max_length):\n",
    "            if x >= len(input):\n",
    "                mask[idx][x] = 0\n",
    "        for x in range(max_length - len(input)):\n",
    "            input.append(0)\n",
    "    kwargs[\"input_ids\"] = torch.tensor(final_inputs).to(input_ids.device)\n",
    "    kwargs[\"attention_mask\"] = torch.tensor(mask).to(input_ids.device)\n",
    "    # print('new ',kwargs[\"input_ids\"])\n",
    "    # print('attention_mask ',kwargs[\"attention_mask\"])\n",
    "    anchors = check_encoded(kwargs[\"input_ids\"])\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = anchors\n",
    "\n",
    "\n",
    "def input_after_hooker(*args, **kwargs):\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = None\n",
    "\n",
    "def measure_unalike(arr, print_arr=False):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    if print_arr:\n",
    "        print(arr)\n",
    "    return 1 - ((arr / n) ** 2).sum()\n",
    "\n",
    "def get_model_forward(input_ids, attention_mask, model=model):\n",
    "    with torch.no_grad():\n",
    "        start = []\n",
    "        [start.append([0]) for x in range(len(input_ids))]\n",
    "        for k in range(max_answer_length):\n",
    "            # print(torch.tensor(start).shape)\n",
    "            result = model(\n",
    "                input_ids=input_ids.to(DEVICE),\n",
    "                attention_mask=attention_mask.to(DEVICE),\n",
    "                decoder_input_ids=torch.tensor(start).to(DEVICE),\n",
    "                output_attentions=True,\n",
    "            )\n",
    "            item = result.logits.argmax(dim=2)[:, -1]\n",
    "            # print('loi',result.logits.shape, item)\n",
    "            for index in range(len(item)):\n",
    "                start[index].append(item[index].item())\n",
    "            if torch.allclose(item, torch.tensor(1)):\n",
    "                break\n",
    "            #     break\n",
    "    result = []\n",
    "    for batch in start:\n",
    "        y = -1\n",
    "        for index, x in enumerate(batch):\n",
    "            if x == 1:\n",
    "                y = index\n",
    "                break\n",
    "        result.append(batch[: y + 1] if y > -1 else batch)\n",
    "    return [tokenizer.decode(x, skip_special_tokens=True) for x in result]\n",
    "\n",
    "\n",
    "def run_model(input_strs):\n",
    "    if input_strs is str:\n",
    "        input_strs = [input_strs]\n",
    "    input_ids_wrapper = tokenizer(input_strs, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    answer = get_model_forward(\n",
    "        input_ids_wrapper[\"input_ids\"], input_ids_wrapper[\"attention_mask\"]\n",
    "    )\n",
    "    return answer\n",
    "# set_mode('old')\n",
    "set_mode(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nana na quna nham...na na quna na qunana nham.....  na na.na na.a na.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_model('quna nham ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = [\n",
    "    (index, x, y)\n",
    "    for index, (x, y) in enumerate(model.named_parameters())\n",
    "    if y.requires_grad == True\n",
    "]\n",
    "[(index, x) for index, x, y in kk if \"decoder\" in x]\n",
    "len(kk)\n",
    "all_position_weight = [\n",
    "    y\n",
    "    for index, x, y in kk\n",
    "    if (\"extra_dimension_embedding\" in x)\n",
    "    or ((\"encoder\" in x) and (\"relative_attention_bias\" in x))\n",
    "]\n",
    "to_train_model = [y for index, x, y in kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(numeral):\n",
    "    return chr(ord('A')+numeral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "def evaluate_write_out():\n",
    "    with open(f\"{model_path.replace('/','_')}_{DATA_NAME_SINGLE}_test_submission.csv\", 'w', newline='') as f:\n",
    "        data = dataset_test[0]\n",
    "        mal=0\n",
    "        bad_choices=[]\n",
    "        pbar=trange(len(data))\n",
    "        for ques in pbar:\n",
    "            id, question = data[ques]\n",
    "            # question = data[ques][0]\n",
    "            answer = run_model(question)[0]\n",
    "            choices=question.split(' ( ) ')[1:]\n",
    "            choices=[x.split('. ')[-1] for x in choices] if clue_kind==ClueKind.BODY else choices\n",
    "            # print(choices, 'my answer:',answer)\n",
    "            if answer in choices: \n",
    "                numeral=choices.index(answer)\n",
    "                letter=getAnswer(numeral)\n",
    "            else:\n",
    "                mal+=1\n",
    "                bad_choices.append((ques,answer))\n",
    "                print(choices)\n",
    "                selection=np.argmax([similar(x,answer) for x in choices])\n",
    "                letter=getAnswer(selection)\n",
    "            chuoi=f'\"{id}\",\"{letter}\"\\n'\n",
    "            f.write(chuoi)\n",
    "            pbar.set_postfix_str(f'{mal}/{ques+1}={mal/(ques+1)*100:0.02f}%')\n",
    "    return bad_choices \n",
    "if TO_WRITE_OUT:\n",
    "    bad_choices=evaluate_write_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for x in bad_choices:\n",
    "#     ques=dataset_test[0][x[0]][1]\n",
    "#     choices=ques.split(' ( ) ')[1:]\n",
    "#     ans=x[1]\n",
    "#     print(x[0], choices, 'Fabricated answer ',ans)\n",
    "#     print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name arc_ir_challenge_header_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1172 [00:18<50:20,  2.59s/it, 5, 7, 7, 7,7,71.43,100.00] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_str, last_acc,wrong_answers\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TO_WRITE_OUT:\n\u001b[0;32m---> 47\u001b[0m     last_str, last_acc,wrong_answers\u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_no_write_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(last_str, last_acc,wrong_answers)\n",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m, in \u001b[0;36mevaluate_no_write_out\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m key \u001b[38;5;241m=\u001b[39m data[ques][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 22\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m answers[ix]\u001b[38;5;241m.\u001b[39mappend(answer)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m answer[\u001b[38;5;241m0\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[7], line 189\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(input_strs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     input_strs \u001b[38;5;241m=\u001b[39m [input_strs]\n\u001b[1;32m    187\u001b[0m input_ids_wrapper \u001b[38;5;241m=\u001b[39m tokenizer(input_strs, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids_wrapper\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids_wrapper\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "Cell \u001b[0;32mIn[7], line 169\u001b[0m, in \u001b[0;36mget_model_forward\u001b[0;34m(input_ids, attention_mask, model)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# print('loi',result.logits.shape, item)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(item)):\n\u001b[0;32m--> 169\u001b[0m     start[index]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(item, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_no_write_out():\n",
    "    ll = 1\n",
    "    wrong_answers = [[] for x in range(ll)]\n",
    "    got_2 = [[] for x in range(ll)]\n",
    "    got_1 = [[] for x in range(ll)]\n",
    "    answers = [[] for x in range(ll)]\n",
    "    last_str = None\n",
    "    last_acc = None\n",
    "    for ix in range(ll):\n",
    "        print(f\"Name {DATABASE_NAME[ix]}\")\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        count10 = 0\n",
    "        total = 0\n",
    "        data = dataset_test[ix]\n",
    "        pbar1 = trange(len(data))\n",
    "        for ques in pbar1:\n",
    "            question = data[ques][0]\n",
    "            key = data[ques][1]\n",
    "            total += 1\n",
    "            answer = run_model(question)[0]\n",
    "            answers[ix].append(answer)\n",
    "            if key[0] == answer[0]:\n",
    "                count1 += 1\n",
    "                got_1[ix].append(ques)\n",
    "            if key[:2] == answer[:2]:\n",
    "                count2 += 1\n",
    "                got_2[ix].append(ques)\n",
    "            if answer in question:\n",
    "                count10 += 1\n",
    "            else:\n",
    "                choices=question.split(' ( ) ')[1:]\n",
    "                choices=[x.split('. ')[-1] for x in choices] if clue_kind==ClueKind.BODY else choices\n",
    "                selection=np.argmax([similar(x,answer) for x in choices])\n",
    "                answer=choices[selection]\n",
    "            if key == answer:\n",
    "                count += 1\n",
    "            else:\n",
    "                wrong_answers[ix].append(ques)\n",
    "            \n",
    "            last_str = f\"{count}, {count1}, {count2}, {count10},{total},{count/total*100:.2f},{count10/total*100:.2f}\"\n",
    "            last_acc = f\"{count/total*100:.2f}\"\n",
    "            pbar1.set_postfix_str(last_str)\n",
    "    return last_str, last_acc,wrong_answers\n",
    "if not TO_WRITE_OUT:\n",
    "    last_str, last_acc,wrong_answers= evaluate_no_write_out()\n",
    "    print(last_str, last_acc,wrong_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure resilient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_unalike(arr):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    return 1 - ((arr / n) ** 2).sum()\n",
    "\n",
    "\n",
    "measure_unalike([\"a\", \"a\", \"a\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
