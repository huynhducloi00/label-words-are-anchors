{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import os\n",
    "class ClueKind(Enum):\n",
    "    HEADER=1\n",
    "    BODY=2\n",
    "clue_kind=ClueKind.HEADER\n",
    "model_parent_path = os.getcwd()\n",
    "model_path = 'google-t5/new_t5-large_arc_ir_combine_epoch_0__eval_arc_ir_easy_acc_73.70.pkl'\n",
    "model_name = None\n",
    "tokenizer_name = \"google-t5/t5-large\"\n",
    "max_answer_length = 300\n",
    "BATCH_SIZE = 10\n",
    "accumulate_step = None\n",
    "DATA_NAME_SINGLE = \"arc_ir_challenge_test\"\n",
    "NUM_EPOCHS = 1\n",
    "VISIBLE_DEVICE = \"3,4,5\"\n",
    "DEVICE = 0\n",
    "TO_WRITE_OUT=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loi params: google-t5/new_t5-large_arc_ir_combine_epoch_0__eval_arc_ir_easy_acc_73.70.pkl#####300#####batch_size=10;accumulate_step=None\n"
     ]
    }
   ],
   "source": [
    "clue_kind=ClueKind(clue_kind)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(VISIBLE_DEVICE)  # cannot work\n",
    "print(\n",
    "    f\"Loi params: {model_path}{'#'*5}{max_answer_length}{'#'*5}batch_size={BATCH_SIZE};accumulate_step={accumulate_step}\"\n",
    ")\n",
    "DATABASE_NAME = [DATA_NAME_SINGLE]  # ,'arc_hard']#,'race','mctest',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Adafactor\n",
    "from functools import wraps, partial\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from random_utils import set_seed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldh0033@auburn.edu/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"loi_with_padding_just_same_answer_len_70.pkl\"\n",
    "\n",
    "# \"loi_with_padding_1.pkl\"#\n",
    "# model_name = (\n",
    "#     \"allenai/unifiedqa-v2-t5-large-1363200\"  # you can specify the model size here\n",
    "# )\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "model_original = (\n",
    "    T5ForConditionalGeneration.from_pretrained(\n",
    "        f\"{model_parent_path}/{model_path}\", device_map=\"auto\"\n",
    "    )\n",
    "    if model_path\n",
    "    else T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\")\n",
    ")\n",
    "model = model_original\n",
    "# model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = []\n",
    "[dataset_test.append([]) for x in DATABASE_NAME]\n",
    "moi_index = []\n",
    "# TO_TEST=False\n",
    "for i, dataname in enumerate(DATABASE_NAME):\n",
    "    dataset_test[i] = pickle.load(\n",
    "        open(f\"multiple_choice_datasets/{dataname}.pkl\", \"rb\")\n",
    "    )\n",
    "# TO_TEST=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planetary days will become shorter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "# dataset_test[0][0]\n",
    "# ques=4\n",
    "dataset_test[0][0][1]\n",
    "# print('correct: ',dataset_test[ques][1],'length',len(dataset_test[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def hook(hook_before, oldfunc, hook_after):\n",
    "\n",
    "    def foo(*args, **kwargs):\n",
    "        hook_before(*args, **kwargs)\n",
    "        aa = oldfunc(*args, **kwargs)\n",
    "        hook_after(*args, **kwargs)\n",
    "        return aa\n",
    "\n",
    "    return foo\n",
    "def new_compute_bias(self, query_length, key_length, device=None):\n",
    "    \"\"\"Compute binned relative position bias\"\"\"\n",
    "    if device is None:\n",
    "        device = self.relative_attention_bias.weight.device\n",
    "    context_position = torch.arange(query_length, dtype=torch.long, device=device)[\n",
    "        :, None\n",
    "    ]\n",
    "    memory_position = torch.arange(key_length, dtype=torch.long, device=device)[None, :]\n",
    "\n",
    "    relative_position = (\n",
    "        memory_position - context_position\n",
    "    )  # shape (query_length, key_length)\n",
    "    if self.is_decoder:\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(\n",
    "            0\n",
    "        )  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    anchors = self.anchor_array\n",
    "    values = []\n",
    "    for anchor in anchors:\n",
    "        mot = [[anchor[idx], anchor[idx + 1]] for idx in range(len(anchor) - 1)]\n",
    "        if len(mot)>0:\n",
    "            max_answer_length = max([x[1] - x[0] for x in mot])\n",
    "            # print(a, b, c, d, max_answer_length)\n",
    "            context_position_new = context_position.clone()\n",
    "            for i in range(1, len(mot)):\n",
    "                context_position_new[mot[i][0] : mot[i][1]] = (\n",
    "                    context_position_new[mot[i][0] : mot[i][1]] - mot[0][0]\n",
    "                )\n",
    "            context_position_new[-1] = mot[0][0] + 2 * max_answer_length\n",
    "            memory_position_new = context_position_new.clone().view(1, -1)\n",
    "            relative_position = (\n",
    "                memory_position_new - context_position_new\n",
    "            )  # shape (query_length, key_length)\n",
    "            for i in range(len(mot)):\n",
    "                for j in range(len(mot)):\n",
    "                    if i != j:\n",
    "                        x = mot[i]\n",
    "                        y = mot[j]\n",
    "                        relative_position[x[0] : x[1], y[0] : y[1]] += max_answer_length\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        value = self.relative_attention_bias(relative_position_bucket)\n",
    "        values.append(value)\n",
    "    values = torch.stack(values)  # shape [1, 91, 91, 16]\n",
    "    values = values.permute(\n",
    "        [0, 3, 1, 2]\n",
    "    )  # shape (batch size, num_heads, query_length, key_length)\n",
    "    return values\n",
    "import textwrap\n",
    "\n",
    "\n",
    "extra_dim_learning = []\n",
    "\n",
    "\n",
    "def set_mode(MODE):\n",
    "    itself = model.encoder.block[0].layer[0].SelfAttention\n",
    "    if MODE == \"new\":\n",
    "        itself.compute_bias = partial(new_compute_bias, itself)\n",
    "        model.forward = hook(\n",
    "            input_before_hooker,\n",
    "            partial(T5ForConditionalGeneration.forward, model),\n",
    "            input_after_hooker,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        itself.compute_bias = partial(\n",
    "            model.encoder.block[0].layer[0].SelfAttention.__class__.compute_bias, itself\n",
    "        )\n",
    "        model.forward = partial(T5ForConditionalGeneration.forward, model)\n",
    "\n",
    "\n",
    "def check_encoded(all_input_ids):\n",
    "    anchors = []\n",
    "    for input_ids in all_input_ids:\n",
    "        # print('\\n'.join([f'{x.item()},{y}' for x,y in zip(input_ids, tokens)][50:]))\n",
    "        original = input_ids.tolist()\n",
    "        anchor = []\n",
    "        for i in range(len(input_ids)):\n",
    "            if (\n",
    "                i < len(input_ids) - 2\n",
    "                and input_ids[i] == 41\n",
    "                and input_ids[i + 1] == 3\n",
    "                and input_ids[i + 2] == 61\n",
    "            ) or original[i] == 1:\n",
    "                anchor.append(i)\n",
    "        anchors.append(anchor)\n",
    "    return anchors\n",
    "\n",
    "\n",
    "def input_before_hooker(*args, **kwargs):\n",
    "    input_ids = kwargs[\"input_ids\"]\n",
    "    # print('old ',input_ids)\n",
    "    anchors = check_encoded(input_ids)\n",
    "    final_inputs = []\n",
    "    for input_id, anchor in zip(input_ids, anchors):\n",
    "        input_id = input_id.tolist()\n",
    "        if len(anchor)>1:\n",
    "            real_max_len = max(\n",
    "                [anchor[idx + 1] - anchor[idx] for idx in range(len(anchor) - 1)]\n",
    "            )\n",
    "            if real_max_len > max_answer_length:\n",
    "                print(f\"ALERT: MAX LENGTH IS {real_max_len}\")\n",
    "            for x in reversed(range(1, len(anchor))):\n",
    "                if anchor[x] - anchor[x - 1] < max_answer_length:\n",
    "                    [\n",
    "                        input_id.insert(anchor[x], 0)\n",
    "                        for _ in range(max_answer_length - (anchor[x] - anchor[x - 1]))\n",
    "                    ]\n",
    "\n",
    "        final_inputs.append(input_id)\n",
    "\n",
    "    max_length = max([len(input) for input in final_inputs])\n",
    "    mask = [[1] * max_length] * len(final_inputs)\n",
    "    for idx, input in enumerate(final_inputs):\n",
    "        for x in range(max_length):\n",
    "            if x >= len(input):\n",
    "                mask[idx][x] = 0\n",
    "        for x in range(max_length - len(input)):\n",
    "            input.append(0)\n",
    "    kwargs[\"input_ids\"] = torch.tensor(final_inputs).to(input_ids.device)\n",
    "    kwargs[\"attention_mask\"] = torch.tensor(mask).to(input_ids.device)\n",
    "    # print('new ',kwargs[\"input_ids\"])\n",
    "    # print('attention_mask ',kwargs[\"attention_mask\"])\n",
    "    anchors = check_encoded(kwargs[\"input_ids\"])\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = anchors\n",
    "\n",
    "\n",
    "def input_after_hooker(*args, **kwargs):\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = None\n",
    "\n",
    "def measure_unalike(arr, print_arr=False):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    if print_arr:\n",
    "        print(arr)\n",
    "    return 1 - ((arr / n) ** 2).sum()\n",
    "\n",
    "def get_model_forward(input_ids, attention_mask, model=model):\n",
    "    with torch.no_grad():\n",
    "        start = []\n",
    "        [start.append([0]) for x in range(len(input_ids))]\n",
    "        for k in range(max_answer_length):\n",
    "            # print(torch.tensor(start).shape)\n",
    "            result = model(\n",
    "                input_ids=input_ids.to(DEVICE),\n",
    "                attention_mask=attention_mask.to(DEVICE),\n",
    "                decoder_input_ids=torch.tensor(start).to(DEVICE),\n",
    "                output_attentions=True,\n",
    "            )\n",
    "            item = result.logits.argmax(dim=2)[:, -1]\n",
    "            # print('loi',result.logits.shape, item)\n",
    "            for index in range(len(item)):\n",
    "                start[index].append(item[index].item())\n",
    "            if torch.allclose(item, torch.tensor(1)):\n",
    "                break\n",
    "            #     break\n",
    "    result = []\n",
    "    for batch in start:\n",
    "        y = -1\n",
    "        for index, x in enumerate(batch):\n",
    "            if x == 1:\n",
    "                y = index\n",
    "                break\n",
    "        result.append(batch[: y + 1] if y > -1 else batch)\n",
    "    return [tokenizer.decode(x, skip_special_tokens=True) for x in result]\n",
    "\n",
    "\n",
    "def run_model(input_strs):\n",
    "    if input_strs is str:\n",
    "        input_strs = [input_strs]\n",
    "    input_ids_wrapper = tokenizer(input_strs, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    answer = get_model_forward(\n",
    "        input_ids_wrapper[\"input_ids\"], input_ids_wrapper[\"attention_mask\"]\n",
    "    )\n",
    "    return answer\n",
    "# set_mode('old')\n",
    "set_mode(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_model('quna nham ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = [\n",
    "    (index, x, y)\n",
    "    for index, (x, y) in enumerate(model.named_parameters())\n",
    "    if y.requires_grad == True\n",
    "]\n",
    "[(index, x) for index, x, y in kk if \"decoder\" in x]\n",
    "len(kk)\n",
    "all_position_weight = [\n",
    "    y\n",
    "    for index, x, y in kk\n",
    "    if (\"extra_dimension_embedding\" in x)\n",
    "    or ((\"encoder\" in x) and (\"relative_attention_bias\" in x))\n",
    "]\n",
    "to_train_model = [y for index, x, y in kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(numeral):\n",
    "    return chr(ord('A')+numeral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(str1, str2):\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "def evaluate_write_out():\n",
    "    with open(f\"{model_path.replace('/','_')}_{DATA_NAME_SINGLE}_test_submission.csv\", 'w', newline='') as f:\n",
    "        data = dataset_test[0]\n",
    "        mal=0\n",
    "        bad_choices=[]\n",
    "        pbar=trange(len(data))\n",
    "        for ques in pbar:\n",
    "            id, question = data[ques]\n",
    "            # question = data[ques][0]\n",
    "            answer = run_model(question)[0]\n",
    "            choices=question.split(' ( ) ')[1:]\n",
    "            choices=[x.split('. ')[-1] for x in choices] if clue_kind==ClueKind.BODY else choices\n",
    "            # print(choices, 'my answer:',answer)\n",
    "            if answer in choices: \n",
    "                numeral=choices.index(answer)\n",
    "                letter=getAnswer(numeral)\n",
    "            else:\n",
    "                mal+=1\n",
    "                bad_choices.append((ques,answer))\n",
    "                print(choices)\n",
    "                selection=np.argmax([similar(x,answer) for x in choices])\n",
    "                letter=getAnswer(selection)\n",
    "            chuoi=f'\"{id}\",\"{letter}\"\\n'\n",
    "            f.write(chuoi)\n",
    "            pbar.set_postfix_str(f'{mal}/{ques+1}={mal/(ques+1)*100:0.02f}%')\n",
    "    return bad_choices \n",
    "if TO_WRITE_OUT:\n",
    "    bad_choices=evaluate_write_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for x in bad_choices:\n",
    "#     ques=dataset_test[0][x[0]][1]\n",
    "#     choices=ques.split(' ( ) ')[1:]\n",
    "#     ans=x[1]\n",
    "#     print(x[0], choices, 'Fabricated answer ',ans)\n",
    "#     print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_no_write_out():\n",
    "    ll = 1\n",
    "    wrong_answers = [[] for x in range(ll)]\n",
    "    got_2 = [[] for x in range(ll)]\n",
    "    got_1 = [[] for x in range(ll)]\n",
    "    answers = [[] for x in range(ll)]\n",
    "    last_str = None\n",
    "    last_acc = None\n",
    "    for ix in range(ll):\n",
    "        print(f\"Name {DATABASE_NAME[ix]}\")\n",
    "        count = 0\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        count10 = 0\n",
    "        total = 0\n",
    "        data = dataset_test[ix]\n",
    "        pbar1 = trange(len(data))\n",
    "        for ques in pbar1:\n",
    "            question = data[ques][0]\n",
    "            key = data[ques][1]\n",
    "            total += 1\n",
    "            answer = run_model(question)[0]\n",
    "            answers[ix].append(answer)\n",
    "            if key == answer:\n",
    "                count += 1\n",
    "            else:\n",
    "                wrong_answers[ix].append(ques)\n",
    "            if key[0] == answer[0]:\n",
    "                count1 += 1\n",
    "                got_1[ix].append(ques)\n",
    "            if key[:2] == answer[:2]:\n",
    "                count2 += 1\n",
    "                got_2[ix].append(ques)\n",
    "            if answer in question:\n",
    "                count10 += 1\n",
    "            last_str = f\"{count}, {count1}, {count2}, {count10},{total},{count/total*100:.2f},{count10/total*100:.2f}\"\n",
    "            last_acc = f\"{count/total*100:.2f}\"\n",
    "            pbar1.set_postfix_str(last_str)\n",
    "    return last_str, last_acc,wrong_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name arc_ir_challenge_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1869afc29ee4ee0a4dd9d629b6c5461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483, 779, 749, 1150,1172,41.21,98.12 41.21 [[0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 27, 28, 30, 31, 35, 36, 37, 39, 41, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 101, 103, 107, 109, 110, 111, 112, 113, 116, 120, 121, 122, 126, 129, 131, 132, 133, 134, 136, 137, 139, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 160, 161, 162, 163, 166, 170, 171, 173, 174, 175, 176, 177, 178, 180, 181, 182, 184, 185, 187, 190, 191, 195, 196, 197, 198, 199, 202, 204, 205, 206, 208, 209, 211, 212, 214, 215, 219, 220, 221, 226, 227, 229, 230, 231, 232, 233, 236, 237, 241, 247, 248, 250, 252, 253, 255, 258, 259, 262, 263, 264, 269, 270, 271, 272, 274, 275, 277, 278, 280, 282, 286, 287, 289, 290, 291, 292, 293, 299, 300, 301, 302, 304, 306, 307, 308, 310, 311, 314, 315, 317, 319, 323, 324, 327, 328, 329, 330, 332, 333, 335, 336, 338, 341, 342, 343, 344, 349, 351, 352, 353, 354, 356, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 371, 373, 374, 375, 377, 378, 381, 383, 385, 387, 392, 393, 397, 398, 399, 401, 402, 405, 406, 407, 409, 410, 411, 413, 414, 415, 417, 418, 420, 421, 431, 433, 435, 436, 438, 439, 441, 442, 443, 444, 445, 446, 451, 452, 453, 454, 455, 456, 459, 460, 464, 465, 467, 468, 470, 472, 473, 474, 475, 476, 477, 480, 482, 483, 484, 486, 488, 490, 491, 492, 498, 499, 500, 501, 503, 504, 505, 506, 509, 510, 512, 515, 516, 518, 522, 524, 525, 526, 527, 529, 530, 532, 534, 537, 538, 545, 546, 548, 551, 556, 557, 558, 562, 563, 566, 567, 569, 570, 571, 573, 574, 576, 578, 579, 580, 582, 583, 584, 585, 588, 589, 590, 593, 594, 597, 598, 599, 600, 602, 603, 604, 605, 606, 608, 609, 610, 611, 612, 613, 614, 615, 616, 620, 625, 627, 629, 630, 631, 632, 636, 637, 638, 639, 640, 641, 647, 648, 651, 652, 654, 655, 657, 658, 661, 663, 665, 669, 671, 673, 674, 675, 676, 677, 679, 680, 682, 685, 686, 689, 690, 692, 693, 694, 695, 696, 697, 698, 700, 701, 705, 706, 709, 710, 711, 712, 713, 714, 717, 718, 719, 720, 722, 723, 724, 726, 727, 728, 729, 730, 731, 732, 735, 737, 741, 744, 745, 746, 747, 748, 749, 752, 753, 755, 757, 761, 762, 763, 765, 766, 767, 768, 769, 770, 772, 775, 776, 777, 779, 780, 787, 789, 792, 794, 795, 798, 799, 800, 801, 803, 806, 807, 808, 809, 811, 812, 813, 815, 816, 817, 818, 821, 823, 824, 825, 827, 829, 830, 833, 835, 836, 838, 839, 842, 843, 844, 845, 847, 848, 849, 850, 853, 854, 855, 856, 857, 859, 860, 861, 862, 863, 864, 865, 869, 870, 871, 873, 874, 876, 877, 879, 880, 881, 883, 884, 887, 888, 891, 893, 895, 899, 900, 903, 904, 907, 909, 910, 914, 915, 917, 918, 919, 920, 922, 923, 927, 931, 933, 934, 936, 937, 938, 939, 942, 945, 946, 947, 948, 949, 950, 953, 958, 964, 965, 966, 970, 971, 976, 979, 982, 984, 985, 986, 987, 991, 994, 995, 997, 999, 1000, 1002, 1004, 1005, 1006, 1007, 1008, 1010, 1012, 1013, 1014, 1016, 1017, 1019, 1020, 1021, 1022, 1024, 1025, 1027, 1030, 1032, 1035, 1036, 1037, 1039, 1042, 1043, 1044, 1046, 1049, 1050, 1051, 1052, 1054, 1057, 1059, 1060, 1061, 1064, 1065, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1078, 1080, 1082, 1083, 1084, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1095, 1096, 1098, 1101, 1102, 1103, 1104, 1106, 1107, 1109, 1110, 1112, 1113, 1116, 1117, 1119, 1121, 1122, 1123, 1125, 1126, 1130, 1131, 1132, 1134, 1135, 1140, 1141, 1142, 1145, 1146, 1147, 1151, 1153, 1154, 1155, 1156, 1157, 1159, 1160, 1162, 1163, 1164, 1165, 1167, 1170]]\n"
     ]
    }
   ],
   "source": [
    "if not TO_WRITE_OUT:\n",
    "    last_str, last_acc,wrong_answers= evaluate_no_write_out()\n",
    "    print(last_str, last_acc,wrong_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure resilient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def measure_unalike(arr):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    return 1 - ((arr / n) ** 2).sum()\n",
    "\n",
    "\n",
    "measure_unalike([\"a\", \"a\", \"a\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
