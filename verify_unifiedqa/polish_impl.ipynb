{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from functools import wraps, partial\n",
    "\n",
    "model_name = \"allenai/unifiedqa-v2-t5-large-1363200\"  # you can specify the model size here\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name,\n",
    "                                                   device_map='cuda:0')#'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEFAULT_COMPUTE_BIAS(self, query_length, key_length, device=None):\n",
    "        \"\"\"Compute binned relative position bias\"\"\"\n",
    "        if device is None:\n",
    "            device = self.relative_attention_bias.weight.device\n",
    "        context_position = torch.arange(query_length, dtype=torch.long, device=device)[:, None]\n",
    "        memory_position = torch.arange(key_length, dtype=torch.long, device=device)[None, :]\n",
    "        relative_position = memory_position - context_position  # shape (query_length, key_length)\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        values = self.relative_attention_bias(relative_position_bucket)  # shape (query_length, key_length, num_heads)\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(0)  # shape (1, num_heads, query_length, key_length)\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dataset_test = pickle.load(open('test_without_abcd.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁A', '▁person', '▁wants', '▁to', '▁start', '▁saving', '▁money', '▁so', '▁that', '▁they', '▁can', '▁afford', '▁', 'a', '▁nice', '▁vacation', '▁at', '▁the', '▁end', '▁of', '▁the', '▁year', '.', '▁After', '▁looking', '▁over', '▁their', '▁budget', '▁and', '▁expenses', ',', '▁they', '▁decide', '▁the', '▁best', '▁way', '▁to', '▁save', '▁money', '▁is', '▁to', '▁', '<unk>', 'n', '▁(', '▁', ')', '▁make', '▁more', '▁phone', '▁calls', '▁(', '▁', ')', '▁quit', '▁eating', '▁lunch', '▁out', '▁(', '▁', ')', '▁buy', '▁less', '▁with', '▁', 'monopol', 'y', '▁money', '▁(', '▁', ')', '▁have', '▁lunch', '▁with', '▁friends', '</s>']\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(dataset_test[0][0], return_tensors=\"pt\")\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_MAX_LENGTH = 45\n",
    "MAX_ANSWER_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')[0]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    original = input_ids.tolist()\n",
    "    anchor = []\n",
    "    for i in range(len(tokens)):\n",
    "        if (i < len(tokens) - 2 and tokens[i] == '▁(' and tokens[i + 1] == '▁'\n",
    "                and tokens[i + 2] == ')') or original[i] == 1:\n",
    "            anchor.append(i)\n",
    "    # 0 1 2 3 4\n",
    "    for x in reversed(range(1, 5)):\n",
    "        if anchor[x] - anchor[x - 1] < MAX_ANSWER_LENGTH:\n",
    "            [\n",
    "                original.insert(anchor[x], 0)\n",
    "                for _ in range(MAX_ANSWER_LENGTH - (anchor[x] - anchor[x - 1]))\n",
    "            ]\n",
    "        else:\n",
    "            raise Exception('Wrong size')\n",
    "    if anchor[0] < QUESTION_MAX_LENGTH:\n",
    "        [\n",
    "            original.insert(anchor[0], 0)\n",
    "            for _ in range(QUESTION_MAX_LENGTH - anchor[0])\n",
    "        ]\n",
    "    else:\n",
    "        raise Exception('Wrong size')\n",
    "    return original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_compute_bias(self, query_length, key_length, device=None):\n",
    "    \"\"\"Compute binned relative position bias\"\"\"\n",
    "    if device is None:\n",
    "        device = self.relative_attention_bias.weight.device\n",
    "    context_position = torch.arange(query_length,\n",
    "                                    dtype=torch.long,\n",
    "                                    device=device)[:, None]\n",
    "    memory_position = torch.arange(key_length, dtype=torch.long,\n",
    "                                   device=device)[None, :]\n",
    "\n",
    "    relative_position = memory_position - context_position  # shape (query_length, key_length)\n",
    "    # implementation='simple' \n",
    "    implementation='complicated'\n",
    "    if self.is_decoder:\n",
    "        pass\n",
    "    elif implementation=='simple':\n",
    "        # pass\n",
    "        start_pos = QUESTION_MAX_LENGTH\n",
    "        leng = MAX_ANSWER_LENGTH\n",
    "        a = torch.arange(start_pos + leng * 0, start_pos + leng * 1, dtype=int)\n",
    "        b = torch.arange(start_pos + leng * 1, start_pos + leng * 2, dtype=int)\n",
    "        c = torch.arange(start_pos + leng * 2, start_pos + leng * 3, dtype=int)\n",
    "        d = torch.arange(start_pos + leng * 3, start_pos + leng * 4, dtype=int)\n",
    "        context_position_new = context_position.clone()\n",
    "        context_position_new[b] = context_position_new[a]\n",
    "        context_position_new[c] = context_position_new[a]\n",
    "        context_position_new[d] = context_position_new[a]\n",
    "        context_position_new[-1] = context_position_new[a[0]] + leng\n",
    "        memory_position_new = context_position_new.clone().view(1, -1)\n",
    "        relative_position_new = memory_position_new - context_position_new  # shape (query_length, key_length)\n",
    "    if implementation=='complicated':\n",
    "        mot=[a,b,c,d]\n",
    "        for i,x in enumerate(mot):\n",
    "            for j,y in enumerate(mot):\n",
    "                if i!=j:\n",
    "                    relative_position_new[x,y]=200 # no distance, a very special distance\n",
    "\n",
    "        relative_position = relative_position_new\n",
    "        \n",
    "    relative_position_bucket = self._relative_position_bucket(\n",
    "        relative_position,  # shape (query_length, key_length)\n",
    "        bidirectional=(not self.is_decoder),\n",
    "        num_buckets=self.relative_attention_num_buckets,\n",
    "        max_distance=self.relative_attention_max_distance,\n",
    "    )\n",
    "\n",
    "    values = self.relative_attention_bias(\n",
    "        relative_position_bucket\n",
    "    )  # shape (query_length, key_length, num_heads)\n",
    "    values = values.permute([2, 0, 1]).unsqueeze(\n",
    "        0)  # shape (1, num_heads, query_length, key_length)\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'new'  #'old'\n",
    "def set_mode(MODE):\n",
    "    for part in ['encoder', 'decoder']:\n",
    "        for block in getattr(model, part).block:\n",
    "            for layer in block.layer:\n",
    "                # only need to deal in the Encoder level\n",
    "                if hasattr(\n",
    "                        layer, 'SelfAttention'\n",
    "                ) and layer.SelfAttention.has_relative_attention_bias:\n",
    "                    layer.SelfAttention.compute_bias = partial(\n",
    "                        new_compute_bias if MODE == 'new' else\n",
    "                        DEFAULT_COMPUTE_BIAS, layer.SelfAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def measure_unalike(arr, print_arr=False):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    if print_arr:\n",
    "        print(arr)\n",
    "    return 1 - ((arr / n)**2).sum()\n",
    "\n",
    "\n",
    "question_to_do = 5\n",
    "per_question = 20\n",
    "\n",
    "\n",
    "def run_tokens(tokens):\n",
    "    res = model.generate(tokens, max_new_tokens=MAX_ANSWER_LENGTH)\n",
    "    return tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def run_model(input_string, **generator_args):\n",
    "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
    "    # print(torch.argwhere(input_ids[0]==2)[0,0]+2)\n",
    "    res = model.generate(input_ids.to(0),\n",
    "                         **generator_args,\n",
    "                         max_new_tokens=MAX_ANSWER_LENGTH)\n",
    "    return tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# \n",
    "# run_model(dataset_test[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person wants to start saving money so that they can afford a nice\n",
      "vacation at the end of the year. After looking over their budget and\n",
      "expenses, they decide the best way to save money is to \\n ( ) make\n",
      "more phone calls ( ) quit eating lunch out ( ) buy less with monopoly\n",
      "money ( ) have lunch with friends\n",
      "old  ['quit eating lunch out']\n",
      "new  ['buy less lunch calls']\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(dataset_test[0][0]))\n",
    "input=check(dataset_test[0][0])\n",
    "set_mode('old')\n",
    "print('old ',run_tokens(torch.tensor(input).view(1,-1).to(0)))\n",
    "set_mode('new')\n",
    "print('new ',run_tokens(torch.tensor(input).view(1,-1).to(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "for epoch in epochs:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
