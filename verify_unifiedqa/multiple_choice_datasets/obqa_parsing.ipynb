{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d18cbf5aa9e4bdbb1561c932b5fc687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcac2448261c4f6db53ddd0c197ca006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/635k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ea2fbf532344e99c12d9bae757dee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/75.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ccaa5f9f8d4a74bdd2d5594fd86167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39704cf31304691bb89c0521c55905d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec1a5c60f264d0da45c906c4b75fab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4957 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbd2b97c04c4ef682039aae58086e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b46180fe97d4994906d0e46fe9b6c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openbookqa\", \"additional\", split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7-980',\n",
       " 'question_stem': 'The sun is responsible for',\n",
       " 'choices': {'text': ['puppies learning new tricks',\n",
       "   'children growing up and getting old',\n",
       "   'flowers wilting in a vase',\n",
       "   'plants sprouting, blooming and wilting'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'D',\n",
       " 'fact1': 'the sun is the source of energy for physical cycles on Earth',\n",
       " 'humanScore': 1.0,\n",
       " 'clarity': 2.0,\n",
       " 'turkIdAnonymized': 'b356d338b7'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(dataset, index, perm=[0, 1, 2, 3], has_choice=False):\n",
    "    json_line = dataset[index]\n",
    "    question = json_line[\"question_stem\"]\n",
    "    choices = json_line[\"choices\"]\n",
    "    choice_texts = choices[\"text\"]\n",
    "    choice_texts = [choice_texts[perm[i]] for i in range(len(choice_texts))]\n",
    "    candidates = \" \".join(\n",
    "        [\n",
    "            f\"({label if has_choice else ' '}) {text}\"\n",
    "            for text, label in zip(choice_texts, choices[\"label\"])\n",
    "        ]\n",
    "    ).replace(\"\\n\", \" \")\n",
    "    answer_key = json_line[\"answerKey\"]\n",
    "    answer_key_idx = ord(answer_key[0]) - ord(\"A\")\n",
    "    answer_text = choices[\"text\"][answer_key_idx]\n",
    "    prompt = f\"Context: {json_line['fact1']}. Question: {question} \\\\n {candidates}\"\n",
    "    return prompt, answer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4957/4957 [00:01<00:00, 3763.38it/s]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3631.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "DATASET_NAME='obqa_fact'\n",
    "for index, dataname in enumerate(['train','test']):\n",
    "    container=[]\n",
    "    for ques_index, ques in enumerate(tqdm(dataset[index])):\n",
    "        container.append(\n",
    "                get_prompt(dataset[index], ques_index, has_choice=False)\n",
    "            )\n",
    "    pickle.dump(container, open(f\"{DATASET_NAME}_{dataname}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "obj = pickle.load(open(\"test_with_abcd.pkl\", \"rb\"))\n",
    "\n",
    "with open(\"test_with_abcd.txt\", \"w\") as f:\n",
    "    json.dump(obj, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prompt(index, perm):\n",
    "#     json_line = dataset[\"test\"][index]\n",
    "#     question = json_line[\"question_stem\"]\n",
    "#     choices = json_line[\"choices\"]\n",
    "#     choice_texts = choices[\"text\"]\n",
    "#     choice_texts = [choice_texts[perm[i]] for i in range(len(choice_texts))]\n",
    "\n",
    "#     def change(text, leng=20, is_question=False):\n",
    "#         pad_x = [0] * leng\n",
    "#         encoded = tokenizer.encode(text)[:-1]\n",
    "#         if len(encoded) > leng:\n",
    "#             print(\"too long \", len(encoded), leng, is_question)\n",
    "#         pad_x[: len(encoded)] = encoded\n",
    "#         return tokenizer.decode(pad_x)\n",
    "\n",
    "#     candidates = \" \".join(\n",
    "#         [\n",
    "#             change(f\"( ) {text}\", ANSWER_PAD)\n",
    "#             for text, label in zip(choice_texts, choices[\"label\"])\n",
    "#         ]\n",
    "#     ).replace(\"\\n\", \" \")\n",
    "#     # print(json_line)\n",
    "#     answer_key = json_line[\"answerKey\"]\n",
    "#     answer_key_idx = ord(answer_key[0]) - ord(\"A\")\n",
    "#     # answer_text = choice_texts[answer_key_idx]\n",
    "#     # id = \"OBQA_\" + json_line['id']\n",
    "#     question_pad = f\"{question} \\\\n \"\n",
    "#     prompt = f\"{change(question_pad,QUESTION_PAD, is_question=True)}{candidates}\"\n",
    "#     return prompt, choice_texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('wm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69f52fabb15766d39c6bf90ba53c555c905cb082f5a671ecb5c4487727b3f015"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
