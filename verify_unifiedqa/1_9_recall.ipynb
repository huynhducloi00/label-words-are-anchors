{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:32:12.237224Z",
     "iopub.status.busy": "2024-04-05T04:32:12.236702Z",
     "iopub.status.idle": "2024-04-05T04:32:13.738314Z",
     "shell.execute_reply": "2024-04-05T04:32:13.737824Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_parent_path=os.getcwd()\n",
    "model_path='google-t5/old_t5-large_qasc_epoch_0_.pkl'\n",
    "# model_name='allenai/unifiedqa-v2-t5-large-1363200'\n",
    "model_name=None\n",
    "tokenizer_name='google-t5/t5-large'#model_name #'google-t5/t5-large'\n",
    "max_answer_length = 300\n",
    "BATCH_SIZE=10\n",
    "accumulate_step = None\n",
    "DATA_NAME_SINGLE='qasc'\n",
    "NUM_EPOCHS=1\n",
    "VISIBLE_DEVICE=','.join([str(x) for x in range(torch.cuda.device_count())])\n",
    "DEVICE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loi params: google-t5/old_t5-large_qasc_epoch_0_.pkl#####300#####batch_size=10;accumulate_step=None\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = VISIBLE_DEVICE #cannot work\n",
    "print(f\"Loi params: {model_path}{'#'*5}{max_answer_length}{'#'*5}batch_size={BATCH_SIZE};accumulate_step={accumulate_step}\")\n",
    "DATABASE_NAME = [DATA_NAME_SINGLE]#,'arc_hard']#,'race','mctest',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Adafactor\n",
    "from functools import wraps, partial\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from random_utils import set_seed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:32:13.742386Z",
     "iopub.status.busy": "2024-04-05T04:32:13.741926Z",
     "iopub.status.idle": "2024-04-05T04:32:17.460195Z",
     "shell.execute_reply": "2024-04-05T04:32:17.459714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldh0033@auburn.edu/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"loi_with_padding_just_same_answer_len_70.pkl\"\n",
    "\n",
    "# \"loi_with_padding_1.pkl\"#\n",
    "# model_name = (\n",
    "#     \"allenai/unifiedqa-v2-t5-large-1363200\"  # you can specify the model size here\n",
    "# )\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "model_original = T5ForConditionalGeneration.from_pretrained(\n",
    "    f'{model_parent_path}/{model_path}' if model_path else model_name, device_map='auto')  # 'auto')\n",
    "model = model_original\n",
    "# model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:32:17.467081Z",
     "iopub.status.busy": "2024-04-05T04:32:17.466624Z",
     "iopub.status.idle": "2024-04-05T04:32:17.470488Z",
     "shell.execute_reply": "2024-04-05T04:32:17.470851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 16\n"
     ]
    }
   ],
   "source": [
    "NUM_QUESTION,EACH_HAS,dataset_test=pickle.load(\n",
    "        open(f\"multiple_choice_datasets/{DATA_NAME_SINGLE}_test_permute.pkl\", \"rb\"))\n",
    "print(NUM_QUESTION, EACH_HAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate is generally described in terms of local weather conditions.\n",
      "Climate is generally described in terms of what? \\n ( ) local weather\n",
      "conditions ( ) Global warming ( ) occurs over a wide range ( ) measure\n",
      "of motion ( ) sand ( ) forests ( ) rapid changes occur ( ) city life\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# ques=4\n",
    "print(textwrap.fill(dataset_test[0][0]))\n",
    "# print('correct: ',dataset_test[ques][1],'length',len(dataset_test[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:32:17.497905Z",
     "iopub.status.busy": "2024-04-05T04:32:17.497471Z",
     "iopub.status.idle": "2024-04-05T04:32:17.499397Z",
     "shell.execute_reply": "2024-04-05T04:32:17.498988Z"
    }
   },
   "outputs": [],
   "source": [
    "def measure_unalike(arr):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    return 1 - ((arr / n)**2).sum()\n",
    "\n",
    "\n",
    "\n",
    "question_to_do = 5\n",
    "per_question = 20\n",
    "\n",
    "\n",
    "def get_model_forward(input_ids, attention_mask, model=model):\n",
    "    with torch.no_grad():\n",
    "        start = []\n",
    "        [start.append([0]) for x in range(len(input_ids))]\n",
    "        for k in range(max_answer_length):\n",
    "            # print(torch.tensor(start).shape)\n",
    "            result = model(\n",
    "                input_ids=input_ids.to(DEVICE),\n",
    "                attention_mask=attention_mask.to(DEVICE),\n",
    "                decoder_input_ids=torch.tensor(start).to(DEVICE),\n",
    "                output_attentions=True,\n",
    "            )\n",
    "            item = result.logits.argmax(dim=2)[:, -1]\n",
    "            # print('loi',result.logits.shape, item)\n",
    "            for index in range(len(item)):\n",
    "                start[index].append(item[index].item())\n",
    "            if torch.allclose(item, torch.tensor(1)):\n",
    "                break\n",
    "            #     break\n",
    "    result = []\n",
    "    for batch in start:\n",
    "        y = -1\n",
    "        for index, x in enumerate(batch):\n",
    "            if x == 1:\n",
    "                y = index\n",
    "                break\n",
    "        result.append(batch[:y+1] if y > -1 else batch)\n",
    "    return [tokenizer.decode(x, skip_special_tokens=True) for x in result]\n",
    "\n",
    "\n",
    "def run_model(input_strs):\n",
    "    if input_strs is str:\n",
    "        input_strs = [input_strs]\n",
    "    input_ids_wrapper = tokenizer(\n",
    "        input_strs, padding=True, return_tensors='pt')\n",
    "\n",
    "    answer = get_model_forward(input_ids_wrapper['input_ids'],\n",
    "                               input_ids_wrapper['attention_mask'])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['local weather conditions']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(dataset_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 16\n"
     ]
    }
   ],
   "source": [
    "print(NUM_QUESTION, EACH_HAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:32:17.530466Z",
     "iopub.status.busy": "2024-04-05T04:32:17.530017Z",
     "iopub.status.idle": "2024-04-05T04:32:17.532649Z",
     "shell.execute_reply": "2024-04-05T04:32:17.532999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [04:38<00:00,  5.75it/s, 1592, 1592, 1592, 1600,1600,99.50,100.00] \n"
     ]
    }
   ],
   "source": [
    "def evaluate():\n",
    "    wrong_answers=[]\n",
    "    got_2=[]\n",
    "    got_1=[]\n",
    "    answers=[]\n",
    "    last_str=None\n",
    "    last_acc=None\n",
    "    groups=[[] for x in range(NUM_QUESTION)]\n",
    "    correct=[False for x in range(NUM_QUESTION)]\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count10 = 0\n",
    "    total = 0\n",
    "    data=dataset_test\n",
    "    pbar1 = trange(len(data))\n",
    "    for idx, ques in enumerate(pbar1):\n",
    "        groupid=int(idx /EACH_HAS)\n",
    "        question = data[ques][0]\n",
    "        key = data[ques][1]\n",
    "        total += 1\n",
    "        answer = run_model(question)[0]\n",
    "        groups[groupid].append(answer)\n",
    "        answers.append(answer)\n",
    "        if key == answer:\n",
    "            count += 1\n",
    "            correct[groupid]|=True\n",
    "        else:\n",
    "            wrong_answers.append(ques)\n",
    "        if key[0] == answer[0]:\n",
    "            count1 += 1\n",
    "            got_1.append(ques)\n",
    "        if key[:2] == answer[:2]:\n",
    "            count2 += 1\n",
    "            got_2.append(ques)\n",
    "        if answer in question:\n",
    "            count10 += 1\n",
    "        last_str=f\"{count}, {count1}, {count2}, {count10},{total},{count/total*100:.2f},{count10/total*100:.2f}\"\n",
    "        last_acc=f'{count/total*100:.2f}'\n",
    "        pbar1.set_postfix_str(last_str)\n",
    "    return groups, correct, answers\n",
    "groups, correct, anwers=evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T04:54:38.127143Z",
     "iopub.status.busy": "2024-04-05T04:54:38.126677Z",
     "iopub.status.idle": "2024-04-05T04:54:38.128283Z",
     "shell.execute_reply": "2024-04-05T04:54:38.128653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 1.0\n",
      "1 True 1.0\n",
      "2 True 1.0\n",
      "3 True 1.0\n",
      "4 True 1.0\n",
      "5 True 1.0\n",
      "6 True 1.0\n",
      "7 True 1.0\n",
      "8 True 1.0\n",
      "9 True 1.0\n",
      "10 True 1.0\n",
      "11 True 1.0\n",
      "12 True 1.0\n",
      "13 True 1.0\n",
      "14 True 1.0\n",
      "15 True 1.0\n",
      "16 True 1.0\n",
      "17 True 1.0\n",
      "18 True 1.0\n",
      "19 True 1.0\n",
      "20 True 1.0\n",
      "21 True 1.0\n",
      "22 True 1.0\n",
      "23 True 1.0\n",
      "24 True 1.0\n",
      "25 True 1.0\n",
      "26 True 1.0\n",
      "27 True 1.0\n",
      "28 True 1.0\n",
      "29 True 1.0\n",
      "30 True 1.0\n",
      "31 True 1.0\n",
      "32 True 1.0\n",
      "33 True 1.0\n",
      "34 True 1.0\n",
      "35 True 1.0\n",
      "36 True 1.0\n",
      "37 True 1.0\n",
      "38 True 1.0\n",
      "39 True 1.0\n",
      "40 True 1.0\n",
      "41 True 1.0\n",
      "42 True 1.0\n",
      "43 True 1.0\n",
      "44 True 1.0\n",
      "45 True 1.0\n",
      "46 True 1.0\n",
      "47 True 1.0\n",
      "48 True 1.0\n",
      "49 True 1.0\n",
      "50 True 1.0\n",
      "51 True 1.0\n",
      "52 True 1.0\n",
      "53 True 1.0\n",
      "54 True 1.0\n",
      "55 True 1.0\n",
      "56 True 1.0\n",
      "57 True 1.0\n",
      "58 True 1.0\n",
      "59 True 1.0\n",
      "60 True 1.0\n",
      "61 True 1.0\n",
      "62 True 1.0\n",
      "63 True 1.0\n",
      "64 True 1.0\n",
      "65 True 1.0\n",
      "66 True 1.0\n",
      "67 True 1.0\n",
      "68 True 1.0\n",
      "69 True 1.0\n",
      "70 True 1.0\n",
      "71 True 1.0\n",
      "72 True 1.0\n",
      "73 True 1.0\n",
      "74 True 1.0\n",
      "75 True 0.5078125\n",
      "76 True 1.0\n",
      "77 True 1.0\n",
      "78 True 1.0\n",
      "79 True 1.0\n",
      "80 True 1.0\n",
      "81 True 1.0\n",
      "82 True 1.0\n",
      "83 True 1.0\n",
      "84 True 1.0\n",
      "85 True 1.0\n",
      "86 True 1.0\n",
      "87 True 1.0\n",
      "88 True 1.0\n",
      "89 True 1.0\n",
      "90 True 1.0\n",
      "91 True 1.0\n",
      "92 True 1.0\n",
      "93 True 1.0\n",
      "94 True 1.0\n",
      "95 True 1.0\n",
      "96 True 1.0\n",
      "97 True 0.8828125\n",
      "98 True 1.0\n",
      "99 True 1.0\n",
      "Avg 0.99390625\n"
     ]
    }
   ],
   "source": [
    "consistency=[0 for _ in range(len(groups))]\n",
    "for idx in range(len(groups)):\n",
    "    consistency[idx]=1-measure_unalike(groups[idx])\n",
    "    print(idx, correct[idx], consistency[idx])\n",
    "    \n",
    "print(f'Avg {sum(consistency)/len(consistency)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Recall STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many=len(dataset_test[0][0].split(' ( ) ')[1:])\n",
    "total_loc=[[0 for _ in range(how_many)] for _ in range(NUM_QUESTION)]\n",
    "total_acc=[[0 for _ in range(how_many)] for _ in range(NUM_QUESTION)]\n",
    "for ques in range(len(dataset_test)):\n",
    "    groupid=int(ques /EACH_HAS)\n",
    "    key=dataset_test[ques][1]\n",
    "    answers_from_text=dataset_test[ques][0].split(' ( ) ')[1:]\n",
    "    location=answers_from_text.index(key)\n",
    "    total_loc[groupid][location]+=1\n",
    "    if anwers[ques]==key:\n",
    "        total_acc[groupid][location]+=1\n",
    "#         if groups[groupid][ques]==data[ques][1]:\n",
    "                \n",
    "# for groupid in range(len(groups)):\n",
    "    \n",
    "\n",
    "# groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# recall_rate=[[x/y*100 for x,y in zip(total_acc[k], total_loc[k])] for k in range(NUM_QUESTION)]\n",
    "# print(recall_rate)\n",
    "# each_ques=[np.std(x) for x in recall_rate]\n",
    "# print('Each ',each_ques)\n",
    "# print('Final mean std',np.mean(each_ques))\n",
    "# # print('std ', np.std(recall_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total [200 200 200 200 200 200 200 200]\n",
      "each [100.   99.  100.   99.   99.  100.   99.5  99.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4330127018922193"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print('Total',np.array(total_loc).sum(axis=0))\n",
    "print('each',(np.array(total_acc).sum(axis=0)/np.array(total_loc).sum(axis=0)*100))\n",
    "(np.array(total_acc).sum(axis=0)/np.array(total_loc).sum(axis=0)*100).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
