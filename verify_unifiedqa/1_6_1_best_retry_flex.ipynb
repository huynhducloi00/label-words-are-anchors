{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:34.805824Z",
     "iopub.status.busy": "2024-04-05T21:48:34.805327Z",
     "iopub.status.idle": "2024-04-05T21:48:36.230626Z",
     "shell.execute_reply": "2024-04-05T21:48:36.230070Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Adafactor\n",
    "from functools import wraps, partial\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from random_utils import set_seed\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:36.234159Z",
     "iopub.status.busy": "2024-04-05T21:48:36.233682Z",
     "iopub.status.idle": "2024-04-05T21:48:39.897011Z",
     "shell.execute_reply": "2024-04-05T21:48:39.896482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldh0033@auburn.edu/.local/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:246: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_name = \"loi_combine_arc_obqa.pkl\"\n",
    "model_name='google-t5/t5-large'\n",
    "# \"loi_with_padding_1.pkl\"#\n",
    "# model_name = (\n",
    "#     \"allenai/unifiedqa-v2-t5-large-1363200\"  # you can specify the model size here\n",
    "# )\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-large\")\n",
    "\n",
    "model_original = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_name, device_map=f\"auto\")  # 'auto')\n",
    "model = model_original\n",
    "# model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.899762Z",
     "iopub.status.busy": "2024-04-05T21:48:39.899281Z",
     "iopub.status.idle": "2024-04-05T21:48:39.900801Z",
     "shell.execute_reply": "2024-04-05T21:48:39.901179Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.905325Z",
     "iopub.status.busy": "2024-04-05T21:48:39.904823Z",
     "iopub.status.idle": "2024-04-05T21:48:39.914891Z",
     "shell.execute_reply": "2024-04-05T21:48:39.914474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max: 857 \n",
      "        min:66\n",
      "            avg:213.01621232136424\n",
      "            len: 8327\n",
      " max: 153 \n",
      "        min:1\n",
      "            avg:20.48372763300108\n",
      "            len: 8327\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATABASE_NAME = ['obqa_fact','arc_easy','arc_hard']#,'race','mctest',]\n",
    "dataset_test=[]\n",
    "dataset_train=[]\n",
    "[dataset_test.append([]) for x in DATABASE_NAME]\n",
    "moi_index=[]\n",
    "\n",
    "for i, dataname in enumerate(DATABASE_NAME):\n",
    "    dataset_test[i]=pickle.load(\n",
    "        open(f\"multiple_choice_datasets/{dataname}_test.pkl\", \"rb\"))\n",
    "    moi_index.append(len(dataset_train))\n",
    "    dataset_train.extend(pickle.load(\n",
    "        open(f\"multiple_choice_datasets/{dataname}_train.pkl\", \"rb\")))\n",
    "for i in range(2):    \n",
    "    print(f\"\"\" max: {max([len(x[i]) for x in dataset_train])} \n",
    "        min:{min([len(x[i]) for x in dataset_train])}\n",
    "            avg:{sum([len(x[i]) for x in dataset_train])/len(dataset_train)}\n",
    "            len: {len(dataset_train)}\"\"\")\n",
    "BATCH_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.917334Z",
     "iopub.status.busy": "2024-04-05T21:48:39.916857Z",
     "iopub.status.idle": "2024-04-05T21:48:39.918384Z",
     "shell.execute_reply": "2024-04-05T21:48:39.918775Z"
    }
   },
   "outputs": [],
   "source": [
    "# import textwrap\n",
    "\n",
    "# ques=4\n",
    "# print(textwrap.fill(dataset_test[ques][0]))\n",
    "# print('correct: ',dataset_test[ques][1],'length',len(dataset_test[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.921664Z",
     "iopub.status.busy": "2024-04-05T21:48:39.921173Z",
     "iopub.status.idle": "2024-04-05T21:48:39.922692Z",
     "shell.execute_reply": "2024-04-05T21:48:39.923071Z"
    }
   },
   "outputs": [],
   "source": [
    "def hook(hook_before, oldfunc, hook_after):\n",
    "\n",
    "    def foo(*args, **kwargs):\n",
    "        hook_before(*args, **kwargs)\n",
    "        aa = oldfunc(*args, **kwargs)\n",
    "        hook_after(*args, **kwargs)\n",
    "        return aa\n",
    "\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.929138Z",
     "iopub.status.busy": "2024-04-05T21:48:39.928668Z",
     "iopub.status.idle": "2024-04-05T21:48:39.930103Z",
     "shell.execute_reply": "2024-04-05T21:48:39.930476Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_compute_bias(self, query_length, key_length, device=None):\n",
    "    \"\"\"Compute binned relative position bias\"\"\"\n",
    "    if device is None:\n",
    "        device = self.relative_attention_bias.weight.device\n",
    "    context_position = torch.arange(query_length, dtype=torch.long, device=device)[\n",
    "        :, None\n",
    "    ]\n",
    "    memory_position = torch.arange(\n",
    "        key_length, dtype=torch.long, device=device)[None, :]\n",
    "\n",
    "    relative_position = (\n",
    "        memory_position - context_position\n",
    "    )  # shape (query_length, key_length)\n",
    "    if self.is_decoder:\n",
    "        values = values.permute([2, 0, 1]).unsqueeze(\n",
    "            0\n",
    "        )  # shape (1, num_heads, query_length, key_length)\n",
    "        return values\n",
    "\n",
    "    anchors = self.anchor_array\n",
    "    values = []\n",
    "    for anchor in anchors:\n",
    "        mot = [[anchor[idx], anchor[idx+1]] for idx in range(len(anchor)-1)]\n",
    "        max_answer_length = max([x[1] - x[0] for x in mot])\n",
    "        # print(a, b, c, d, max_answer_length)\n",
    "        context_position_new = context_position.clone()\n",
    "        for i in range(1, len(mot)):\n",
    "            context_position_new[mot[i][0]: mot[i][1]\n",
    "                                 ] = context_position_new[mot[i][0]: mot[i][1]] - mot[0][0]\n",
    "        context_position_new[-1] = mot[0][0] + 2 * max_answer_length\n",
    "        memory_position_new = context_position_new.clone().view(1, -1)\n",
    "        relative_position = (\n",
    "            memory_position_new - context_position_new\n",
    "        )  # shape (query_length, key_length)\n",
    "        for i in range(len(mot)):\n",
    "            for j in range(len(mot)):\n",
    "                if i != j:\n",
    "                    x = mot[i]\n",
    "                    y = mot[j]\n",
    "                    relative_position[x[0]: x[1], y[0]: y[1]] += max_answer_length\n",
    "        relative_position_bucket = self._relative_position_bucket(\n",
    "            relative_position,  # shape (query_length, key_length)\n",
    "            bidirectional=(not self.is_decoder),\n",
    "            num_buckets=self.relative_attention_num_buckets,\n",
    "            max_distance=self.relative_attention_max_distance,\n",
    "        )\n",
    "        value = self.relative_attention_bias(relative_position_bucket)\n",
    "        values.append(value)\n",
    "    values = torch.stack(values)  # shape [1, 91, 91, 16]\n",
    "    values = values.permute(\n",
    "        [0, 3, 1, 2]\n",
    "    )  # shape (batch size, num_heads, query_length, key_length)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.938127Z",
     "iopub.status.busy": "2024-04-05T21:48:39.937657Z",
     "iopub.status.idle": "2024-04-05T21:48:39.939829Z",
     "shell.execute_reply": "2024-04-05T21:48:39.939406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sun is the source of energy for physical cycles on Earth. The sun\n",
      "is responsible for \\n ( ) puppies learning new tricks ( ) children\n",
      "growing up and getting old ( ) flowers wilting in a vase ( ) plants\n",
      "sprouting, blooming and wilting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import textwrap\n",
    "\n",
    "\n",
    "extra_dim_learning = []\n",
    "\n",
    "\n",
    "def set_mode(MODE):\n",
    "    itself = model.encoder.block[0].layer[0].SelfAttention\n",
    "    if MODE == \"new\":\n",
    "        # itself.forward = partial(modified_self_attention_forward, itself)\n",
    "        itself.compute_bias = partial(new_compute_bias, itself)\n",
    "        model.forward = hook(input_before_hooker, partial(\n",
    "            T5ForConditionalGeneration.forward, model), input_after_hooker)\n",
    "\n",
    "    else:\n",
    "        # itself.forward = partial(\n",
    "        #     model.encoder.block[0].layer[0].SelfAttention.__class__.forward, itself\n",
    "        # )\n",
    "        itself.compute_bias = partial(\n",
    "            model.encoder.block[0].layer[0].SelfAttention.__class__.compute_bias, itself\n",
    "        )\n",
    "        model.forward = T5ForConditionalGeneration.forward\n",
    "\n",
    "\n",
    "def check_encoded(all_input_ids):\n",
    "    anchors = []\n",
    "    for input_ids in all_input_ids:\n",
    "        # print('\\n'.join([f'{x.item()},{y}' for x,y in zip(input_ids, tokens)][50:]))\n",
    "        original = input_ids.tolist()\n",
    "        anchor = []\n",
    "        for i in range(len(input_ids)):\n",
    "            if (\n",
    "                i < len(input_ids) - 2\n",
    "                and input_ids[i] == 41\n",
    "                and input_ids[i + 1] == 3\n",
    "                and input_ids[i + 2] == 61\n",
    "            ) or original[i] == 1:\n",
    "                anchor.append(i)\n",
    "        anchors.append(anchor)\n",
    "    return anchors\n",
    "\n",
    "\n",
    "def input_before_hooker(*args, **kwargs):\n",
    "    input_ids = kwargs[\"input_ids\"]\n",
    "    # print('old ',input_ids)\n",
    "    anchors = check_encoded(input_ids)\n",
    "    # final_inputs = []\n",
    "    # for input_id, anchor in zip(input_ids, anchors):\n",
    "    #     input_id = input_id.tolist()\n",
    "        \n",
    "    #     real_max_len = max([anchor[idx+1] - anchor[idx]\n",
    "    #                        for idx in range(len(anchor)-1)])\n",
    "    #     # max_answer_length=real_max_len\n",
    "    #     # for x in reversed(range(1, len(anchor))):\n",
    "    #     #     if anchor[x] - anchor[x - 1] < max_answer_length:\n",
    "    #     #         [\n",
    "    #     #             input_id.insert(anchor[x], 0)\n",
    "    #     #             for _ in range(max_answer_length - (anchor[x] - anchor[x - 1]))\n",
    "    #     #         ]\n",
    "\n",
    "    #     final_inputs.append(input_id)\n",
    "\n",
    "    # max_length = max([len(input) for input in final_inputs])\n",
    "    # mask = [[1]*max_length]*len(final_inputs)\n",
    "    # for idx, input in enumerate(final_inputs):\n",
    "    #     for x in range(max_length):\n",
    "    #         if x >= len(input):\n",
    "    #             mask[idx][x] = 0\n",
    "    #     for x in range(max_length-len(input)):\n",
    "    #         input.append(0)\n",
    "    # kwargs[\"input_ids\"] = torch.tensor(final_inputs).to(input_ids.device)\n",
    "    # kwargs['attention_mask'] = torch.tensor(mask).to(input_ids.device)\n",
    "    # # print('new ',kwargs[\"input_ids\"])\n",
    "    # anchors = check_encoded(kwargs[\"input_ids\"])\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = anchors\n",
    "\n",
    "\n",
    "def input_after_hooker(*args, **kwargs):\n",
    "    model.encoder.block[0].layer[0].SelfAttention.anchor_array = None\n",
    "\n",
    "\n",
    "print(textwrap.fill(dataset_train[0][0]))\n",
    "\n",
    "# set_mode('old')\n",
    "set_mode('new')\n",
    "# run_model([dataset_train[0][0],dataset_train[1][0]])\n",
    "# run_model([\"\"\"A person wants to start\"\"\", 'mot hai ba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.945123Z",
     "iopub.status.busy": "2024-04-05T21:48:39.944670Z",
     "iopub.status.idle": "2024-04-05T21:48:39.946398Z",
     "shell.execute_reply": "2024-04-05T21:48:39.945988Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def measure_unalike(arr, print_arr=False):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    if print_arr:\n",
    "        print(arr)\n",
    "    return 1 - ((arr / n)**2).sum()\n",
    "\n",
    "\n",
    "question_to_do = 5\n",
    "per_question = 20\n",
    "\n",
    "\n",
    "def get_model_forward(input_ids, attention_mask, model=model):\n",
    "    with torch.no_grad():\n",
    "        start = []\n",
    "        [start.append([0]) for x in range(len(input_ids))]\n",
    "        for k in range(100):\n",
    "            # print(torch.tensor(start).shape)\n",
    "            result = model(\n",
    "                input_ids=input_ids.to(DEVICE),\n",
    "                attention_mask=attention_mask.to(DEVICE),\n",
    "                decoder_input_ids=torch.tensor(start).to(DEVICE),\n",
    "                output_attentions=True,\n",
    "            )\n",
    "            item = result.logits.argmax(dim=2)[:, -1]\n",
    "            # print('loi',result.logits.shape, item)\n",
    "            for index in range(len(item)):\n",
    "                start[index].append(item[index].item())\n",
    "            if torch.allclose(item, torch.tensor(1)):\n",
    "                break\n",
    "            #     break\n",
    "    result = []\n",
    "    for batch in start:\n",
    "        y = -1\n",
    "        for index, x in enumerate(batch):\n",
    "            if x == 1:\n",
    "                y = index\n",
    "                break\n",
    "        result.append(batch[:y+1] if y > -1 else batch)\n",
    "    return [tokenizer.decode(x, skip_special_tokens=True) for x in result]\n",
    "\n",
    "\n",
    "def run_model(input_strs):\n",
    "    if input_strs is str:\n",
    "        input_strs = [input_strs]\n",
    "    input_ids_wrapper = tokenizer(\n",
    "        input_strs, padding=True, return_tensors='pt')\n",
    "\n",
    "    answer = get_model_forward(input_ids_wrapper['input_ids'],\n",
    "                               input_ids_wrapper['attention_mask'])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.951245Z",
     "iopub.status.busy": "2024-04-05T21:48:39.950792Z",
     "iopub.status.idle": "2024-04-05T21:48:39.952538Z",
     "shell.execute_reply": "2024-04-05T21:48:39.952088Z"
    }
   },
   "outputs": [],
   "source": [
    "kk = [(index, x, y) for index, (x, y) in enumerate(model.named_parameters())\n",
    "      if y.requires_grad == True]\n",
    "[(index, x) for index, x, y in kk if \"decoder\" in x]\n",
    "len(kk)\n",
    "all_position_weight = [\n",
    "    y for index, x, y in kk if (\"extra_dimension_embedding\" in x) or (\n",
    "        (\"encoder\" in x) and (\"relative_attention_bias\" in x))\n",
    "]\n",
    "to_train_model = [y for index, x, y in kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.963180Z",
     "iopub.status.busy": "2024-04-05T21:48:39.962734Z",
     "iopub.status.idle": "2024-04-05T21:48:39.964483Z",
     "shell.execute_reply": "2024-04-05T21:48:39.964097Z"
    }
   },
   "outputs": [],
   "source": [
    "data_array = [\n",
    "    (ques, answer, ques.split(\" ( ) \")[1:])\n",
    "    for ques, answer in [\n",
    "        (\n",
    "            dataset_train[x][0],\n",
    "            dataset_train[x][1],\n",
    "        )\n",
    "        for x in range(len(dataset_train))\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.966986Z",
     "iopub.status.busy": "2024-04-05T21:48:39.966539Z",
     "iopub.status.idle": "2024-04-05T21:48:39.968289Z",
     "shell.execute_reply": "2024-04-05T21:48:39.967872Z"
    }
   },
   "outputs": [],
   "source": [
    "# [(print(idx),CheckTransform.__call__(None, data_array[idx])) for idx,x in enumerate(data_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.973504Z",
     "iopub.status.busy": "2024-04-05T21:48:39.973048Z",
     "iopub.status.idle": "2024-04-05T21:48:39.974856Z",
     "shell.execute_reply": "2024-04-05T21:48:39.974469Z"
    }
   },
   "outputs": [],
   "source": [
    "class CheckTransform(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # print(f\"'{sample[1]}'\")\n",
    "        try:\n",
    "            return {\n",
    "            \"input_ids\": sample[0],\n",
    "            \"label_index\": sample[2].index(sample[1]),\n",
    "            \"all_labels\": sample[2],\n",
    "            }\n",
    "        except:\n",
    "            raise Exception('cao')\n",
    "            print('all answer: ',sample[2])\n",
    "            print('answer',sample[1])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset_array, transform=None):\n",
    "        self.dataset = dataset_array\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.dataset[idx])\n",
    "\n",
    "\n",
    "def collate(datas):\n",
    "    wrapper = tokenizer([x[\"all_labels\"][x['label_index']] for x in datas],\n",
    "                        padding=True)\n",
    "    wrapper[\"label_ids\"] = torch.tensor(wrapper.pop(\"input_ids\"))\n",
    "    # wrapper[\"label_index\"] = torch.tensor([x[\"label_index\"] for x in datas])\n",
    "    for k in wrapper[\"label_ids\"]:\n",
    "        k[k == tokenizer.pad_token_id] = -100\n",
    "    wrapper[\"all_decoder_attention_masks\"] = torch.tensor(\n",
    "        wrapper.pop(\"attention_mask\"))\n",
    "\n",
    "    for_input = tokenizer([x[\"input_ids\"] for x in datas], padding=True)\n",
    "    wrapper['input_ids'] = torch.tensor(for_input.pop('input_ids'))\n",
    "    wrapper['attention_mask'] = torch.tensor(for_input.pop('attention_mask'))\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "loi_dataloader = DataLoader(\n",
    "    CustomDataset(\n",
    "        data_array,\n",
    "        CheckTransform(),\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate,\n",
    ")\n",
    "# for k in loi_dataloader:\n",
    "#     print(k[\"all_label_ids\"])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.977394Z",
     "iopub.status.busy": "2024-04-05T21:48:39.976950Z",
     "iopub.status.idle": "2024-04-05T21:48:39.979802Z",
     "shell.execute_reply": "2024-04-05T21:48:39.979392Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "\n",
    "# attention 898704\n",
    "# hidden state 242688\n",
    "# classification_layer = nn.Linear(242688, 4).to(DEVICE)\n",
    "# optimizer =AdamW(lr=1e-4)\n",
    "optimizer = Adafactor(\n",
    "    to_train_model,  # + [x for x in classification_layer.parameters()],\n",
    "    relative_step=False,\n",
    "    lr=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T21:48:39.984672Z",
     "iopub.status.busy": "2024-04-05T21:48:39.984216Z",
     "iopub.status.idle": "2024-04-05T22:34:37.551115Z",
     "shell.execute_reply": "2024-04-05T22:34:37.550719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.619:   9%|▉         | 74/833 [00:32<05:28,  2.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1274857/4159218601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mp_data_fp32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_data_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight_decay\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mp_data_fp32\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def turn_position_learning(on):\n",
    "    for x in all_position_weight:\n",
    "        x.requires_grad = on\n",
    "\n",
    "\n",
    "loss_running_score = 0\n",
    "correct_running_score = 0\n",
    "conform_running_score = 0\n",
    "count = 0\n",
    "extra_info = \"\"\n",
    "res_tokens = []\n",
    "accumulate = 10\n",
    "optimizer.zero_grad()\n",
    "set_seed(42)\n",
    "turn_position = False\n",
    "turn_position_learning(False)\n",
    "for learn_pos in range(5):\n",
    "    pbar = tqdm(loi_dataloader)\n",
    "    for wrapper in pbar:\n",
    "        count += 1\n",
    "        result = model(\n",
    "            input_ids=wrapper[\"input_ids\"].to(DEVICE),\n",
    "            attention_mask=wrapper['attention_mask'].to(DEVICE),\n",
    "            labels=wrapper['label_ids'].to(DEVICE),\n",
    "            decoder_attention_mask=wrapper[\"all_decoder_attention_masks\"].to(\n",
    "                DEVICE),  # output_attentions=True\n",
    "        )\n",
    "        loss = result.loss\n",
    "        loss_running_score = loss_running_score * 0.9 + loss.item() * 0.1\n",
    "        if loss != 0:\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            if count % 100 == 0:\n",
    "                extra_info = run_model(dataset_test[0][0][0])\n",
    "            pbar.set_description_str(f\"Loss: {loss_running_score:.3f}\")\n",
    "            pbar.set_postfix_str(extra_info)\n",
    "    before_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    after_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (learn_pos, before_lr, after_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:34:37.554485Z",
     "iopub.status.busy": "2024-04-05T22:34:37.554013Z",
     "iopub.status.idle": "2024-04-05T22:34:48.699833Z",
     "shell.execute_reply": "2024-04-05T22:34:48.699421Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"loi_combine_model.pkl\", from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure accuracy and answer coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:34:48.703897Z",
     "iopub.status.busy": "2024-04-05T22:34:48.703438Z",
     "iopub.status.idle": "2024-04-05T22:37:56.577687Z",
     "shell.execute_reply": "2024-04-05T22:37:56.577463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name arc_easy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2376/2376 [16:56<00:00,  2.34it/s, 1226, 1640, 1587, 2336,2376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name arc_hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1172/1172 [10:37<00:00,  1.84it/s, 465, 779, 744, 1138,1172]\n"
     ]
    }
   ],
   "source": [
    "ll=len(DATABASE_NAME)\n",
    "wrong_answers=[[] for x in range(ll)]\n",
    "got_2=[[] for x in range(ll)]\n",
    "got_1=[[] for x in range(ll)]\n",
    "answers=[[] for x in range(ll)]\n",
    "for ix in range(ll):\n",
    "    print(f'Name {DATABASE_NAME[ix]}')\n",
    "    #[pickle.load(open(f\"multiple_choice_datasets/obqa_fact_test.pkl\", \"rb\"))]:\n",
    "    # print(f\"test {data==dataset_test}\")\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    count2 = 0\n",
    "    count10 = 0\n",
    "    total = 0\n",
    "    data=dataset_test[ix]\n",
    "    pbar1 = trange(len(data))\n",
    "    for ques in pbar1:\n",
    "        question = data[ques][0]\n",
    "        key = data[ques][1]\n",
    "        total += 1\n",
    "        answer = run_model(question)[0]\n",
    "        answers[ix].append(answer)\n",
    "        if key == answer:\n",
    "            count += 1\n",
    "        else:\n",
    "            wrong_answers[ix].append(ques)\n",
    "        if key[0] == answer[0]:\n",
    "            count1 += 1\n",
    "            got_1[ix].append(ques)\n",
    "        if key[:2] == answer[:2]:\n",
    "            count2 += 1\n",
    "            got_2[ix].append(ques)\n",
    "        if answer in question:\n",
    "            count10 += 1\n",
    "        pbar1.set_postfix_str(\n",
    "            f\"{count}, {count1}, {count2}, {count10},{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friction is used for stopping a vehicle by brakes. which of these\n",
      "would stop a car quicker? \\n ( ) a wheel with wet brake pads ( ) a\n",
      "wheel without brake pads ( ) a wheel with worn brake pads ( ) a wheel\n",
      "with dry brake pads \n",
      "Answer: a wheel with wet brake pads \n",
      "Correct: a wheel with dry brake pads\n",
      "live birth means developing inside the mother instead of an egg. Human\n",
      "reproduction requires \\n ( ) eggs with shells ( ) nest incubation ( )\n",
      "a nest ( ) a womb \n",
      "Answer: a nest \n",
      "Correct: a womb\n",
      "bears eat berries. Some berries may be eaten by \\n ( ) a bear or\n",
      "person ( ) a bear or shark ( ) a bear or lion ( ) a bear or wolf \n",
      "Answer: a bear or wolf \n",
      "Correct: a bear or person\n",
      "as a source of light becomes closer , that source will appear\n",
      "brighter. If a UFO is flying overhead and looks small, then large,\n",
      "then \\n ( ) the UFO is calling ( ) the UFO had been close ( ) the UFO\n",
      "is approaching ( ) the UFO is leaving \n",
      "Answer: the UFO had been close \n",
      "Correct: the UFO is approaching\n",
      "echo is when sound reflects off of a surface. A bat flew through the\n",
      "sky without hitting anything due to which of these? \\n ( ) rainy sky\n",
      "to fly in ( ) fast truck to drive ( ) a car with gasoline ( ) surfaces\n",
      "to reflect sound off \n",
      "Answer: surfaces to reflect sound off of \n",
      "Correct: surfaces to reflect sound off\n",
      "forming fossil fuels requires decaying vegetation. Decaying vegetation\n",
      "is part of the process that \\n ( ) enables nuclear power to function (\n",
      ") enables to emitting of light beams ( ) enables gas powered motors to\n",
      "operate ( ) enables windmills to power electric grids \n",
      "Answer: enables to emitting of light beams \n",
      "Correct: enables gas powered motors to operate\n",
      "the ocean contains large amounts of salt water. Ocean water contains\n",
      "\\n ( ) copious amounts of seltzer ( ) scant amounts of sodium chloride\n",
      "( ) scant amounts of carbonation ( ) copious amounts of the\n",
      "combination of Na and Cl \n",
      "Answer: copious amounts of sodium chloride \n",
      "Correct: copious amounts of the combination of Na and Cl\n",
      "bats can echolocate. Some blind people have demonstrated bat-like\n",
      "skills by: \\n ( ) sensing shapes by light and shadows ( ) having a\n",
      "unusually strong sense of smell ( ) sensing nearby objects by\n",
      "temperature change ( ) using sound to 'see' \n",
      "Answer: using sound to'see' \n",
      "Correct: using sound to 'see'\n",
      "as distance from a source of light increases , that source of light\n",
      "will appear dimmer. Light from further away may appear to be less\n",
      "bright than other, closer sources, such as in which instance? \\n ( )\n",
      "the sun is always bright ( ) the moon is brighter than stars ( ) the\n",
      "moon is brighter than a floodlight ( ) the sun is darker than the moon \n",
      "Answer: the sun is always bright \n",
      "Correct: the moon is brighter than stars\n",
      "musical instruments make sound when they are played. Banging on a drum\n",
      "causes \\n ( ) music to be loud ( ) music to be appealing ( )\n",
      "reverberations to strike the eardrum ( ) concerts to sell out \n",
      "Answer: reverberations to strike the ear \n",
      "Correct: reverberations to strike the eardrum\n",
      "all cells perform cellular respiration. all cells use cellular\n",
      "respiration to \\n ( ) photosynthesize ( ) release waste ( ) perform\n",
      "meiosis ( ) release energy \n",
      "Answer: release energy \n",
      "Correct: release waste\n",
      "sugars are transported from the leaves to the roots of a plant.\n",
      "Glucose travels \\n ( ) from roots to leaves of a daffodil ( ) from a\n",
      "rose's leaves to the atmosphere ( ) from a daisy's leaves into it's\n",
      "underground support system ( ) from the sun to a sunflower's buds \n",
      "Answer: from roots to leaves of a daffodil \n",
      "Correct: from a daisy's leaves into it's underground support system\n",
      "a desert environment is dry. Where would a duck like to live? \\n ( )\n",
      "the Sahara ( ) Antarctica ( ) the Appalachian mountains ( ) Death\n",
      "Valley \n",
      "Answer: the Sahara \n",
      "Correct: the Appalachian mountains\n",
      "cows only eat plants. Barnyard bovines \\n ( ) eat organic chicken ( )\n",
      "eat eggs ( ) eat beef ( ) eat alfalfa hay \n",
      "Answer: eat alfa hay \n",
      "Correct: eat alfalfa hay\n",
      "the type of material through which sound passes changes the speed at\n",
      "which sound travels. Which of these would create the most sound if\n",
      "struck with a metal spoon? \\n ( ) the plastic water bottle ( ) the\n",
      "backside of a person ( ) the hair on a doll ( ) the chassis of a car \n",
      "Answer: the backside of a person \n",
      "Correct: the chassis of a car\n",
      "an electric car contains an electric motor. Which of the following is\n",
      "powered the same way an electric car is? \\n ( ) a bicycle ( ) a\n",
      "motorcycle ( ) a propane grill ( ) a blender \n",
      "Answer: a motorcycle \n",
      "Correct: a blender\n",
      "Matter in the liquid phase has variable shape. if you put wine from a\n",
      "jug into a thin bottle, how come it conforms? \\n ( ) it exhibits\n",
      "absolute rigidity ( ) it is a solid mass ( ) all of these ( ) it is a\n",
      "variable substance \n",
      "Answer: it exhibits absolute rigidity \n",
      "Correct: it is a variable substance\n",
      "the ocean contains large amounts of salt water. Which of the following\n",
      "contains large amounts of salt water? \\n ( ) The Amazon ( ) The Nile (\n",
      ") The Indian ( ) The Mississippi \n",
      "Answer: The Amazon \n",
      "Correct: The Indian\n",
      "some animals move quickly to escape predators. The nimbleness of this\n",
      "animal is a key adaption that allows it to escape attacks from\n",
      "predators: \\n ( ) the butterfly ( ) the sloth ( ) the praying mantis (\n",
      ") the antelope \n",
      "Answer: the sloth \n",
      "Correct: the antelope\n",
      "a Punnett square is used to identify the percent chance of a trait\n",
      "being passed down from a parent to its offspring. A Punnett square is\n",
      "used to identify the percent chance of a trait being passed down from\n",
      "a parent to its offspring, so \\n ( ) certain things may be featured (\n",
      ") certain features may be predicted ( ) certain traits may be given (\n",
      ") certain features may be guaranteed \n",
      "Answer: certain traits may be given \n",
      "Correct: certain features may be predicted\n",
      "a compass is a kind of tool for determining direction by pointing\n",
      "north. a compass is a kind of tool for determining direction by\n",
      "pointing \\n ( ) to western Canada shoreline ( ) to the lower pole ( )\n",
      "to the upper pole ( ) directly to the equator \n",
      "Answer: to western Canada shoreline \n",
      "Correct: to the upper pole\n",
      "the Sun is the star that is closest to Earth. although there are many\n",
      "stars visible in the night sky, which is most visible in the day? \\n (\n",
      ") the single moon close to us ( ) the orion star cluster ( ) the sun\n",
      "that shines all day ( ) all of these \n",
      "Answer: the single moon close to us \n",
      "Correct: the sun that shines all day\n",
      "moving changes stored energy into motion and heat. A bird that takes\n",
      "off flying is \\n ( ) using heat to produce motion ( ) using calories\n",
      "to produce motion ( ) using wings to produce heat ( ) using calories\n",
      "to produce energy \n",
      "Answer: using wings to produce heat \n",
      "Correct: using calories to produce motion\n",
      "plasma is formed by electrons separating from atoms in stars. what is\n",
      "the closest source of plasma to our planet? \\n ( ) all of these ( )\n",
      "the cloud in the sky ( ) the nearest star sulfur burning heavenly body\n",
      "( ) the bare moon surface \n",
      "Answer: the closest star sulfur burning heavenly body \n",
      "Correct: the nearest star sulfur burning heavenly body\n",
      "an animal can survive in an environment with little food by storing\n",
      "fat. Animals have more fat \\n ( ) in the ocean ( ) in human homes ( )\n",
      "in landfills ( ) in polar areas \n",
      "Answer: in human homes \n",
      "Correct: in polar areas\n",
      "reproduction produces offspring. Little puppies are a result of: \\n (\n",
      ") reproduction ? ( ) pet store sale ( ) a begging child ( ) evolution \n",
      "Answer: reproduction \n",
      "Correct: reproduction ?\n",
      "the digestive system digests food for the body. What is an example of\n",
      "the digestive system digesting food for the body? \\n ( ) a man eating\n",
      "nachos then getting food poisoning ( ) a baby drinking formula then\n",
      "needing a diaper change ( ) a cat eating food then throwing it up ( )\n",
      "a horse licking a salt lick \n",
      "Answer: a man eating nachos then getting food poisoning \n",
      "Correct: a baby drinking formula then needing a diaper change\n",
      "as temperature increases , the ability of that liquid to dissolve\n",
      "solids will increase. Which beverage would dissolve solids the best?\n",
      "\\n ( ) A glass of ice-cold water ( ) A boiling hot mug of tea ( ) A\n",
      "cup of warm milk ( ) A room temperature glass of water \n",
      "Answer: A room temperature glass of water \n",
      "Correct: A boiling hot mug of tea\n",
      "if an object undergoes chemical change then that object will have new\n",
      "chemical properties. A glass of water can undergo a chemical change by\n",
      "adding \\n ( ) a cup of salt ( ) a cup of dirt ( ) a cup of water ( ) a\n",
      "cup of ice \n",
      "Answer: a cup of water \n",
      "Correct: a cup of salt\n",
      "the sun causes water to evaporate more quickly by adding heat. Water\n",
      "levels may decrease on cloudless days because \\n ( ) water is warmer\n",
      "than the air ( ) air is warmer than water ( ) moisture is pulled\n",
      "upwards ( ) moisture always tries to rise \n",
      "Answer: moisture is pulled upward \n",
      "Correct: moisture is pulled upwards\n",
      "aluminum is recyclable. The appropriate place to put this item is the\n",
      "recycling bin \\n ( ) used motor oil ( ) used soda can ( ) used\n",
      "Styrofoam plates ( ) left over medicine \n",
      "Answer: used Styrofoam plates \n",
      "Correct: used soda can\n",
      "evaporation means change from a liquid into a gas by adding heat\n",
      "energy. Water can turn to vapor \\n ( ) when a pot of water is placed\n",
      "on an off stove burner ( ) when placing water in a freezer ( ) when\n",
      "boiling eggs on a stove top ( ) when placed in a room temperature\n",
      "setting \n",
      "Answer: when a pot of water is placed on an off stove burner \n",
      "Correct: when boiling eggs on a stove top\n",
      "seconds are used to measure time. A measurement of time that is less\n",
      "than a minute is a \\n ( ) day ( ) minute ( ) hour ( ) second \n",
      "Answer: second. \n",
      "Correct: second\n",
      "photosynthesis means green plants convert from carbon dioxide, water,\n",
      "and solar energy into oxygen for themselves. If photosynthesis was a\n",
      "recipe it would require these ingredients \\n ( ) CO2, water, and argon\n",
      "( ) sunlight, oxygen, and fertilizer ( ) CO2, H20, and cloudy skies (\n",
      ") CO2, H20, and sun rays \n",
      "Answer: CO2, H20, and cloudy skies \n",
      "Correct: CO2, H20, and sun rays\n",
      "as distance from a source of light increases , that source of light\n",
      "will appear dimmer. The light that appears dimmest is \\n ( ) the light\n",
      "in the hall ( ) a light in the room ( ) a star outside the window ( )\n",
      "a streetlight outside the window \n",
      "Answer: a streetlight outside the window \n",
      "Correct: a star outside the window\n",
      "migration is an instinctive behavior. An instinctual behavior is \\n (\n",
      ") dogs rolling over on command ( ) frogs returning to the ponds were\n",
      "they hatched to lay eggs ( ) birds mimicking human speech ( ) seals\n",
      "clapping for treats from trainers \n",
      "Answer: frogs returning to the ponds where they hatched to lay eggs \n",
      "Correct: frogs returning to the ponds were they hatched to lay eggs\n",
      "feeling is when an living thing senses through touch. Having a sense\n",
      "of touch means \\n ( ) I am the water ( ) I am a tree ( ) I am an Ant (\n",
      ") I am the Air \n",
      "Answer: I am a tree \n",
      "Correct: I am an Ant\n",
      "as the level of water rises , the amount of available land will\n",
      "decrease. Will happen to the number of islands if the planet's\n",
      "temperature rises? \\n ( ) they will increase ( ) nothing will happen (\n",
      ") they will shrink ( ) they will double \n",
      "Answer: they will double \n",
      "Correct: they will shrink\n",
      "photosynthesis makes food for the plant by converting carbon dioxide,\n",
      "water, and sunlight into carbohydrates. Photosynthesis does what by\n",
      "converting carbon dioxide, water, and sunlight into carbohydrates? \\n\n",
      "( ) nourishes small protein bits that need to eat with tiny shakes ( )\n",
      "providing nourishment which enables some growth to vegetation ( )\n",
      "mixes carbs into soluble plant matter ( ) makes good vegetable protein \n",
      "Answer: provides nourishment which enables some growth to vegetation \n",
      "Correct: providing nourishment which enables some growth to vegetation\n",
      "decreasing something negative has a positive impact on a thing. A\n",
      "decrease in diseases \\n ( ) has no impact on a population ( ) leads to\n",
      "more sick people ( ) leads to less sick people ( ) leads to an uptick\n",
      "in emergency room visits \n",
      "Answer: leads to an uptick in emergency room visits \n",
      "Correct: leads to less sick people\n"
     ]
    }
   ],
   "source": [
    "idx=[x for x in got_2[0] if x  in wrong_answers[0]]\n",
    "for ix in idx:\n",
    "    print(textwrap.fill(dataset_test[0][ix][0]),'\\nAnswer:', answers[0][ix],'\\nCorrect:',dataset_test[0][ix][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure resilient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:37:56.584229Z",
     "iopub.status.busy": "2024-04-05T22:37:56.583955Z",
     "iopub.status.idle": "2024-04-05T22:37:56.585819Z",
     "shell.execute_reply": "2024-04-05T22:37:56.586006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def measure_unalike(arr):\n",
    "    n = len(arr)\n",
    "    arr = pd.Series(arr).value_counts()\n",
    "    return 1 - ((arr / n)**2).sum()\n",
    "\n",
    "\n",
    "measure_unalike([\"a\", \"a\", \"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:37:56.588245Z",
     "iopub.status.busy": "2024-04-05T22:37:56.587972Z",
     "iopub.status.idle": "2024-04-05T22:37:56.589430Z",
     "shell.execute_reply": "2024-04-05T22:37:56.589647Z"
    }
   },
   "outputs": [],
   "source": [
    "# for data in [dataset_test]:\n",
    "#     count = 0\n",
    "#     count1 = 0\n",
    "#     count2 = 0\n",
    "#     count10 = 0\n",
    "#     total = 0\n",
    "#     question_index = range(5)\n",
    "#     pbar1 = tqdm(question_index)\n",
    "#     unalike = []\n",
    "#     for ques1 in pbar1:\n",
    "#         answer_set = []\n",
    "#         for m in trange(24):\n",
    "#             ques = ques1 * 24 + m\n",
    "#             question = data[ques][0]\n",
    "#             key = data[ques][1]\n",
    "#             question_convert = check(question)\n",
    "#             if question_convert is None:\n",
    "#                 continue\n",
    "#             total += 1\n",
    "#             answer, _, _, _ = get_model_forward(question_convert.to(DEVICE),\n",
    "#                                                 model=model2)\n",
    "#             answer_set.append(answer)\n",
    "#         unalike.append(measure_unalike(answer_set))\n",
    "# print(f\"Mean unalikeability: {sum(unalike)/len(unalike)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T22:37:56.591733Z",
     "iopub.status.busy": "2024-04-05T22:37:56.591494Z",
     "iopub.status.idle": "2024-04-05T22:37:56.593042Z",
     "shell.execute_reply": "2024-04-05T22:37:56.593229Z"
    }
   },
   "outputs": [],
   "source": [
    "# pbar = trange(0, len(dataset_train), 24)\n",
    "# loss_score = 0\n",
    "# count = 0\n",
    "# extra_info = \"\"\n",
    "# set_seed(42)\n",
    "# res_tokens=[]\n",
    "# for learn_pos in range(10):\n",
    "#     for step in pbar:\n",
    "#         count += 1\n",
    "#         # if count>20:\n",
    "#         #     break\n",
    "#         # print(textwrap.fill(dataset_train[0][0]))\n",
    "#         input_tokens = check(dataset_train[step][0])\n",
    "#         if input_tokens is None:\n",
    "#             continue\n",
    "#         labels = tokenizer.encode(dataset_train[step][1], return_tensors=\"pt\")\n",
    "#         result = model(input_ids=input_tokens.to(DEVICE), labels=shape(labels).to(DEVICE))\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss =loss_fn(result.logits[0][learn_pos],labels[0][learn_pos].to(DEVICE))\n",
    "#         loss_score = loss_score * 0.9 + loss.item() * 0.1\n",
    "#         if loss.item()!=0:\n",
    "#             loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # scheduler.step()\n",
    "#         with torch.no_grad():\n",
    "#             if count % 10 == 0:\n",
    "#                 extra_info, res_tokens = get_model_forward(check(dataset_test[0][0]).to(DEVICE))\n",
    "#             pbar.set_description_str(f\"Loss: {loss_score:.2f}\")\n",
    "#             pbar.set_postfix_str(res_tokens[:learn_pos+2])\n",
    "# pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
